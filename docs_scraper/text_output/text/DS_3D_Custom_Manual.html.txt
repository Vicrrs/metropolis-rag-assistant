DeepStream-3D Custom Apps and Libs Tutorials — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formDeepStream-3...DeepStream-3D Custom Apps and Libs Tutorials#ds3dframework, interfaces and custom-libs are designed for DeepStream-3D processing.ds3dis agnostic from Gstreamer/Glib frameworks. These interfaces are capble of different types of data fusion. Developers can implement different types of custom libraries fordataloader,datafilteranddatarender. The interface has ABI compatible layers and modern C++ interface. Developers only need to focus on the modern C++ interface for application or custom lib development.DS3Ddataloaderis loaded byGstAppSrc, enabling its utilization for depth cameras like stereo cameras and Time-of-Flight cameras to capture image/depth data or load data from the file system. Additionally, it can be employed for capturing lidar data from sensors or lidar data files.datafilteris loaded by thenvds3dfilterGst-plugin. It could be used for 2D depth data processing , 3D point-cloud data extraction from depth,  other 2D-depth or 3D-points data filters and lidar or 3D data inference.datarenderis loaded byGstAppSink. It could be used for 2D depth rendering and 3D point-cloud and lidar data rendering. It also could be used for file dump.DS3D Application Examples#DeepStream-3D Multi-Modal Lidar and Camera Sensor Fusion Appsample application showcases a multi-modal sensor fusion pipeline for LiDAR and camera data using the DS3D framework. There are 2 examples of multi-modal sensor fusion pipelines inside the samples. The sample app is located at/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-3d-lidar-sensor-fusion.Refer toDeepStream 3D Multi-Modal Lidar and Camera Sensor Fusion Appto see more details ofdeepstream-3d-lidar-sensor-fusionDS3D BEVFusion pipeline shows the overview of 6-camera plus 1-LiDAR data fusion inference and rendering pipeline throughdeepstream-3d-lidar-sensor-fusion.DS3D V2XFusion pipeline shows the overview of 1-camera plus 1-LiDAR with batch 4 data input fusion inference and rendering pipeline throughdeepstream-3d-lidar-sensor-fusion.deepstream-lidar-inferencehas the sample code to load these custom libs and to connect these components together in simple ways. Besides that, DS3D has a simple C++ safe pointer forGstreamercomponents. The interfaces are found in header files located at/opt/nvidia/deepstream/deepstream/sources/libs/ds3d/gst/.The image below shows the overview of lidar 3D data inference and rendering pipeline indeepstream-lidar-inference.See more details in theDeepStream 3D Lidar Inference App.deepstream-3d-depth-camerais another example for ds3d pipeline.The image below shows the overview of depth to 3D point processing pipeline indeepstream-3d-depth-camera.See more details in theDeepStream 3D Depth Camera App.All the components are configured in YAML format. They are loaded byGst-plugins.There are 3 major components, they may all be loaded into the deepstream pipeline.DS3D data formatds3d/datamap#ds3d/datamaprecognizes the data format used in DS3D framework. Data buffers flowing between GStreamer plugins will be of this data-type.ds3d/datamapare key-value pairs where key is a string and value, a pointer, structure or tensor frame to data.
All of the operations on the buffer is managed byGuardDataMap.Examples:Create GuardDataMapdatamapand set scaler key-values.#include<ds3d/common/hpp/datamap.hpp>usingnamespaceds3d;GuardDataMapdatamap(NvDs3d_CreateDataHashMap(),true);// creat a empty datamapTimeStampts{0};datamap.setData("DS3D::Timestamp",ts);// set timestampfloatscore=0.1;datamap.setData("DS3D::Score",score);// copy score into datamapUser-defined structure added into ds3ddatamap.ds3d datamap requires each data type having atypeid:uint64_tbefore adding the data into datamap. This could prevent any wrong datatype casting in runtime. To achieve that, there are 2 ways to enable a typeid for a structure.Example 1, useREGISTER_TYPE_IDdirectly in custom data structure definition. this is mostly used when users define a new structure.#define DS3D_TYPEID_TIMESTAMP 0x20002structTimeStamp{uint64_tt0=0;uint64_tt1=0;uint64_tt2=0;REGISTER_TYPE_ID(DS3D_TYPEID_TIMESTAMP)};// Add the shared_ptr into datamapstd::shared_ptr<TimeStamp>timePtr(newTimeStamp);datamap.setPtrData("DS3D::Timestamp0",timePtr);// Add a copy of the TimeStamp into datamapTimeStamptime1;datamap.setData("DS3D::Timestamp1",time1);Example 2, Instantiate templatestructTpId<>{staticconstexprTIdType__typeid();}, this is helpful when adding a 3rdparty data structure into datamap and not able to modify the 3rd-party existing DataStructure.// this is the 3rd-party structurestructExisting3rdpartData{floatv0;intv1;};// derive ds3d::__TypeID for any 3rdparty data structure.#incude "ds3d/common/type_trait.h"#define DS3D_TYPEID_EXISTING_3RDPART_DATA 0x80001namespaceds3d{template<>structTpId<Existing3rdpartData>:__TypeID<DS3D_TYPEID_EXISTING_3RDPART_DATA>{};}// Add the shared_ptr into datamapstd::shared_ptr<Existing3rdpartData>dataPtr(newExisting3rdpartData);datamap.setPtrData("3rdpartyData0",dataPtr);// Add a copy of the Existing3rdpartData into datamapExisting3rdpartDatadata3rdparty{0.0f,0};datamap.setData("3rdpartyData1",data3rdparty);Create LiDAR tensor frame and add into GuardDataMapdatamap.std::vector<vec4f>lidardata={{{-5.0f,-5.0f,-3.0f,0.6f}},{{-5.0f,-5.0f,-3.0f,0.85f}},{{1.0f,0.5f,-1.0f,0.82f}},{{-5.0f,-5.0f,-3.0f,0.8f}},};void*pointPtr=(void*)(&lidardata[0]);uint32_tpointsN=lidardata.size();FrameGuardlidarFrame=wrapLidarXYZIFrame<float>((void*)pointPtr,pointsN,MemType::kCpu,0,[holder=std::move(lidardata)](void*){});// lambda deleterconststd::stringkeyName="DS3D::LidarXYZI";// user define a key name.// setGuardData holds a reference_count on the lidarFrame without deep-copydatamap.setGuardData(keyName,lidarFrame);Create 2D-Image tensor frame and add into GuardDataMapdatamap.std::vector<vec4b>imagedata={{{255,0,0,255}},{{0,255,0,255}},{{0,255,0,255}},{{0,0,255,255}},{{255,255,0,255}},{{0,255,0,255}},};uint32_twidth=3,height=2;Frame2DPlanecolorPlane={width,height,(uint32_t)sizeof(vec4b)*width,sizeof(vec4b),0};void*colorPtr=(void*)(&imagedata[0]);uint32_tbytes=colorPlane.pitchInBytes*colorPlane.height;Frame2DGuardimageFrame=impl::Wrap2DFrame<uint8_t,FrameType::kColorRGBA>(colorPtr,{colorPlane},bytes,MemType::kCpu,0,[holder=std::move(imagedata)](void*){});// lambda deleterconststd::stringkeyName="DS3D::ColorFrame";// user define a key name.// setGuardData holds a reference_count on the imageFrame without deep-copydatamap.setGuardData(keyName,imageFrame);Create custom shaped tensor frame and add into GuardDataMapdatamap.std::vector<float>tensordata={0,1,2,3,4,5,6,7,8,9,10,11.0f};void*tensorPtr=(void*)(&tensordata[0]);ShapetensorShape{3,{1,3,4}};// tensor shape (1, 3, 4)uint32_tbytes=tensordata.size()*sizeof(tensordata[0]);FrameGuardtensorFrame=impl::WrapFrame<float,FrameType::kCustom>(tensorPtr,bytes,tensorShape,MemType::kCpu,0,[holder=std::move(imagedata)](void*){});// lambda deleterconststd::stringkeyName="DS3D::dataarray";// user define a key name.// setGuardData holds a reference_count on the tensorFrame without deep-copydatamap.setGuardData(keyName,tensorFrame);Query data values from GuardDataMapdatamapGuardDataMap::getGuardData, return a safe reference counted guard data GuardDataT<DataStructure> e.g. Frame2DGuard, FrameGuard, GuardDataT<TimeStamp>GuardDataMap::getPtrData, return a reference counted std::shared_ptr<DataStructure> e.g. std::shared_ptr<TimeStamp>GuardDataMap::getData, return a copy of the DataStructure. e.g. TimeStamp// example to use different ways to get timestamp.std::stringtimeKey="DS3D::Timestamp";if(datamap.hasData(timeKey)){// get a COPY of TimestampTimeStampt0;DS_ASSERT(isGood(datamap.getData(timeKey,t0));// get a std::shared_ptr of Timestampstd::shared_ptr<TimeStamp>tPtr;DS_ASSERT(isGood(datamap.getPtrData(timeKey,tPtr));// get a reference-counted GuardDataT<Timestamp>GuardDataT<TimeStamp>timeGuard;DS_ASSERT(isGood(datamap.getPtrData(timeKey,timeGuard));// example to get a lidar tensor frameFrameGuardpointFrame;std::stringlidarKey="DS3D::LidarXYZI";if(datamap.hasData(lidarKey)){// get lidar tensor frame// pointFrame holds a reference countDS_ASSERT(isGood(dataMap.getGuardData(lidarKey,pointFrame)));DataTypedType=pointFrame->dataType();FrameTypeframeType=pointFrame->frameType();MemTypememType=pointFrame->memType();ShapepShape=pointFrame->shape();void*dataPtr=pointFrame->base();size_tdataBytes=pointFrame->bytes();}// example to get a RGBA image tensor frameFrame2DGuardrgbaImage;std::stringimageKey="DS3D::ColorFrame";if(datamap.hasData(imageKey)){// get 2D image tensor frame// rgbaImage holds a reference countDS_ASSERT(isGood(dataMap.getGuardData(imageKey,rgbaImage)));DataTypedType=rgbaImage->dataType();FrameTypeframeType=rgbaImage->frameType();MemTypememType=rgbaImage->memType();ShapepShape=rgbaImage->shape();void*dataPtr=rgbaImage->base();size_tdataBytes=rgbaImage->bytes();DS_ASSERT(rgbaImage->planes()==1);// RGBA image has 1 plane.Frame2DPlaneplane=rgbaImage->getPlane(0);}// example to get a custom shaped tensor frame, e.g. data_arrayFrameGuardtensorFrame;std::stringtensorKey="DS3D::dataarray";if(datamap.hasData(tensorKey)){// get any tensor frame// tensorFrame holds a reference countDS_ASSERT(isGood(dataMap.getGuardData(tensorKey,tensorFrame)));DataTypedType=tensorFrame->dataType();FrameTypeframeType=tensorFrame->frameType();MemTypememType=tensorFrame->memType();ShapepShape=tensorFrame->shape();void*dataPtr=tensorFrame->base();size_tdataBytes=tensorFrame->bytes();}DS3D DataMap interoperate with GstBuffer#DS3D DataMap has ABI-compatible classds3d::abiRefDataMap. With that,NvDs3DBufferis defined for storing DS3D datamap along withGstBuffer. Header file isds3d/gst/nvds3d_meta.h.struct NvDs3DBuffer {
    uint32_t magicID;  // must be 'DS3D'
    ds3d::abiRefDataMap* datamap;
};WarningDo not use thedatamapdirectly. The easy and safe way to access that is throughGuardDataMap. see examples belowExample to get datamap fromGstBuffer#include<ds3d/common/hpp/datamap.hpp>#include<ds3d/common/hpp/frame.hpp>usingnamespaceds3d;GstBuffer*gstBuf=;// get the gstBuf from probe function or Gstreamer pluginsif(NvDs3D_IsDs3DBuf(gstBuf)){constabiRefDataMap*refDataMap=nullptr;ErrCodec=NvDs3D_Find1stDataMap(gstBuf,refDataMap);if(refDataMap){GuardDataMapdataMap(*refDataMap);FrameGuardlidarFrame;c=dataMap.getGuardData("DS3D::LidarXYZI",pointFrame);// get lidar points reference.FrameGuarduvCoord;c=dataMap.getGuardData("DS3D::TextureCoordKey",uvCoord);// get 3D points UV coordinates reference.Frame2DGuarddepthFrame;c=dataMap.getGuardData("DS3D::DepthFrame",depthFrame);// get depth frame reference.DepthScalescale;c=dataMap.getData("DS3D::DepthScaleUnit",scale);// copy depth scale}}Example to createa ads3d::datamapinto a newGstBuffer#include<ds3d/common/hpp/datamap.hpp>#include<ds3d/common/hpp/frame.hpp>#include<ds3d/common/impl/impl_frames.h>GuardDataMapdatamap(NvDs3d_CreateDataHashMap(),true);// set true to take the reference ownership./* Create color image frame and store them into ds3d datamap. */// Assume format is RGBA{Frame2DPlanecolorPlane={1920,1080,1920*sizeof(uint8_t),sizeof(uint8_t),0};uint32_tcolorBytesPerFrame=colorPlane.pitchInBytes*colorPlane.height;std::vector<uint8_t>data(colorBytesPerFrame);// Image datavoid*dataPtr=&data[0];// create color 2D frameFrame2DGuardframe=Wrap2DFrame<uint8_t,FrameType::kColorRGBA>(dataPtr,{_config.colorPlane},bytesPerFrame,MemType::kCpu,0,[data=std::move(data)](void*){});c=datamap.setGuardData(kColorFrame,colorFrame);// store colorFrame reference into datamap....// check error code}Oncedatamapis ready, you can create a new GstBuffer with DS3D datamap.// ``GuardDataMap datamap`` is readyGstBuffer*gstBuf=nullptr;ErrCodec=NvDs3D_CreateGstBuf(gstBuf,datamap.abiRef(),false);// set false to increase reference count....// check error codeExample to update an existingDS3DGstBufferwith a newds3ddatamap.// Assume ``GuardDataMap datamap`` is ready// Assume ``GstBuffer* gstBuf`` is created by another compomentErrCodec=NvDs3D_UpdateDataMap(gstBuf,datamap.abiRef(),false);// set false to increase reference count....// check error codeds3d::dataloader- Load Custom Lib for Data Capture#Load and Manage DS3D Dataloader#Examples:name: realsense_dataloader
type: ds3d::dataloader
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_dataloader_realsense.so
custom_create_function: createRealsenseDataloader
config_body:
  streams: [color, depth]A customdataloadermust havetype:ds3d::dataloader. It is created by explicit call ofNvDs3D_CreateDataLoaderSrc(srcConfig,loaderSrc,start)with the full compoment YAML content. During this call, thecustom_lib_pathis loaded and a specific data loader is created viacustom_create_function. AGstAppsrcobject is also created intoloaderSrc.gstElement.GstAppsrcmanages theds3d::dataloaderdataflows. Thisds3d::dataloadercomponent could be started automatically bygst-pipelineor manually by the application call.GuardDataLoaderdataloader=loaderSrc.customProcessor;ErrCodec=dataloader.start();To stop thedataloader, user can setGstAppsrcstates toGST_STATE_READYor stop it manually.GuardDataLoaderdataloader=loaderSrc.customProcessor;ErrCodec=dataloader.stop();DS3D Dataloader in DeepStream User Application#DS3D Custom Dataloaders are agnostic from Gstreamer/Glib Framework. But it could be working with Gstramer as well. Theds3d::dataloadercould interactively work with GstAppSrc together. They could be created byNvDs3D_CreateDataLoaderSrc.Examples:#include<ds3d/common/config.h>#include<ds3d/gst/nvds3d_gst_plugin.h>std::stringyamlStr=R"(name: ds3d_lidar_file_sourcetype: ds3d::dataloaderout_caps: ds3d/datamapcustom_lib_path: libnvds_lidarfileread.socustom_create_function: createLidarFileLoaderconfig_body:data_config_file: lidar_data_list.yamlpoints_num: 242180mem_type: gpu # choose [cpu gpu]gpu_id: 0mem_pool_size: 6element_size: 4output_datamap_key: DS3D::LidarXYZI)";ErrCodec=ErrCode::kGood;ComponentConfigconfig;c=parseComponentConfig(yamlStr.c_str(),"./config_lidar_loader.yaml",config);DS_ASSERT(config.type==ComponentType::kDataLoader);DS_ASSERT(config.customLibPath=="libnvds_lidarfileread.so");DS_ASSERT(config.customCreateFunction=="createLidarFileLoader");gst::DataLoaderSrcappLoader;c=NvDs3D_CreateDataLoaderSrc(c,appLoader,true);// get DS3D custom dataloader.GuardDataLoaderdataLoader=appLoader.customProcessor;// get GstAppSrc from this appLoader;GstElement*appsrc=appLoader.gstElement.get();// gstreamer pipeline setup and running.// during each read_data from GstAppSrc callback. it would simultaneously reading data from dataloader// GuardDataMap datamap;// dataloader.read_data(datamap);// DS3D dataloader would stop qutomatically when Gstpipeline is stopped.// But in the case if user want to stop it early or manually.// Obtain DS3D custom dataloader and stop manually.c=dataloader.flush();c=dataloader.stop();GuardDataLoaderprovides safe access toabiDataLoader. Once it’s created, it will maintain the reference pointer to thedataloader.Implement a DS3D Custom Dataloader#Examples:#include<ds3d/common/impl/impl_dataloader.h>classTestTimeDataLoader:publicds3d::impl::SyncImplDataLoader{public:TestTimeDataLoader()=default;protected:ErrCodestartImpl(conststd::string&content,conststd::string&path)override{setOutputCaps("ds3d/datamap");returnErrCode::kGood;}ErrCodereadDataImpl(GuardDataMap&datamap)override{datamap.reset(NvDs3d_CreateDataHashMap());staticuint64_tiTime=0;TimeStampt{iTime++,0,0};datamap.setData("time",t);emitError(ErrCode::kGood,"timstamp added");returnErrCode::kGood;}ErrCodestopImpl()override{returnErrCode::kGood;}ErrCodeflushImpl()override{returnErrCode::kGood;}};DS3D_EXTERN_C_BEGINDS3D_EXPORT_APIabiRefDataLoader*createTestTimeDataloader(){returnNewAbiRef<abiDataLoader>(newTestTimeDataLoader);}DS3D_EXTERN_C_ENDA shown in the example above, You’ll need to derivedataloaderfrom theds3d::impl::SyncImplDataLoaderclass, and implement interfaces for the following:ErrCodestartImpl(conststd::string&content,conststd::string&path)override;ErrCodereadDataImpl(GuardDataMap&datamap)override;ErrCodestopImpl()override;ErrCodeflushImpl()override;ds3d::databridge- Loads Custom Lib for data conversion to and from DS3D.#This plugin and custom lib helps convert data type to and fromds3d/datamapMore details:Gst-nvds3dbridge.ds3d::datafilter-  DS3D Custom DataFilter#DS3D DataFilter is processing inputs fromds3d::datamapand producing outputs input newds3d::datamap. Users can implement custom datafilter lib for their own use case.Create And Manage DS3D Datafilter in DeepStream App#Examples:#include<ds3d/common/config.h>#include<ds3d/gst/nvds3d_gst_ptr.h>#include<ds3d/gst/nvds3d_gst_plugin.h>std::stringyamlStr=R"(name: fusion_inferencetype: ds3d::datafilterin_caps: ds3d/datamapout_caps: ds3d/datamapcustom_lib_path: libnvds_tritoninferfilter.socustom_create_function: createLidarInferenceFilterconfig_body:mem_pool_size: 2model_inputs:config_file: model_config_files/config_triton_bev_fusion_infer_grpc.pbtxt- name: input_image_0datatype: UINT8shape: [1, 900, 1600, 4]from: DS3D::ColorFrame_0+1is_2d_frame: true- name: input_lidardatatype: FP32shape: [242180, 4]from: DS3D::LidarXYZI+0)";gst::ElePtrgstPlugin=gst::elementMake("nvds3dfilter","ds3d-custom-filter");g_object_set(G_OBJECT(gstPlugin.get()),"config-content",yamlStr.c_str(),nullptr);GstElement*ele=gstPlugin.get();A customdatafiltermust havetype:ds3d::datafilter. It is loaded through thenvds3dfilterGst-plugin. It is started bygst_element_set_state(GST_STATE_READY). During this call, thecustom_lib_pathis loaded and a specific data filter is created bycustom_create_function.nvds3dfilterGst-pluginhasconfig-contentandconfig-fileproperties. One of them must be set to create adatafilterobject.Implement a Custom DS3D Datafilter#Examples:#include<ds3d/common/impl/impl_datafilter.h>classTestFakeDataFilter:publicimpl::BaseImplDataFilter{public:TestFakeDataFilter()=default;protected:ErrCodestartImpl(conststd::string&content,conststd::string&path)override{setInputCaps(kFakeCapsMetaName);setOutputCaps(kFakeCapsMetaName);returnErrCode::kGood;}ErrCodeprocessImpl(GuardDataMapdatamap,OnGuardDataCBImploutputDataCb,OnGuardDataCBImplinputConsumedCb)override{DS_ASSERT(datamap);TimeStampt;ErrCodec=datamap.getData("time",t);if(!isGood(c)){returnc;}t.t0+=1;inputConsumedCb(ErrCode::kGood,datamap);c=datamap.setData("time",t);if(!isGood(c)){returnc;}outputDataCb(ErrCode::kGood,datamap);returnErrCode::kGood;}ErrCodeflushImpl()override{returnErrCode::kGood;}ErrCodestopImpl()override{returnErrCode::kGood;}};DS3D_EXTERN_C_BEGINDS3D_EXPORT_APIabiRefdatafilter*createTestFakeDatafilter(){returnNewAbiRef<abidatafilter>(newTestFakeDataFilter);}DS3D_EXTERN_C_ENDAs shown in the example above, you’ll need to derive thedatafilterfrom theds3d::impl::BaseImplDataFilterclass, and implement interfaces for the following:ErrCodestartImpl(conststd::string&content,conststd::string&path)override;ErrCodeprocessImpl(GuardDataMapdatamap,OnGuardDataCBImploutputDataCb,OnGuardDataCBImplinputConsumedCb)override;ErrCodestopImpl()override;ErrCodeflushImpl()override;To load this custom lib throughnvds3dfilterGst-plugin, you’ll also need to export a specific symbolcreateTestFakeDatafilter.ds3d::datarender- Loads DS3D Custom DataRender#DS3D Custom DataRenders are agnostic from Gstreamer/Glib Framework. But it could be working with Gstramer as well. Theds3d::datarendercould interactively work with GstAppSink together. They could be created byNvDs3D_CreateDataRenderSink.Examples:Load And Manage DS3D Datarender#Examples:#include<ds3d/common/config.h>#include<ds3d/gst/nvds3d_gst_plugin.h>std::stringyamlStr=R"(name: lidar_rendertype: ds3d::datarenderin_caps: ds3d/datamapcustom_lib_path: libnvds_3d_gl_datarender.socustom_create_function: createLidarDataRendergst_properties:sync: Trueasync: Falsedrop: Falseconfig_body:title: ds3d-lidar-renderstreams: [lidardata]width: 1280height: 720block: Trueview_position: [0, 0, 60]view_target: [0, 0, 0]view_up: [0, 1, 0]near: 0.3far: 100fov: 50lidar_color: [0, 255, 0]lidar_data_key: DS3D::LidarXYZIelement_size: 4lidar_bbox_key: DS3D::Lidar3DBboxRawDataenable_label: True)";ErrCodec=ErrCode::kGood;ComponentConfigconfig;c=parseComponentConfig(yamlStr.c_str(),"./config_lidar_loader.yaml",config);DS_ASSERT(config.type==ComponentType::kDataRender);DS_ASSERT(config.customLibPath=="libnvds_3d_gl_datarender.so");DS_ASSERT(config.customCreateFunction=="createLidarDataRender");gst::DataRenderSinkappRender;c=NvDs3D_CreateDataRenderSink(config,appRender,true);// get DS3D custom datarender.GuardDataRenderdatarender=appRender.customProcessor;// get GstAppSink from this appRender;GstElement*appsink=appRender.gstElement.get();// gstreamer pipeline setup and running.// during each render_data from GstAppSink callback. it would simultaneously reading data from datarender// datarender.render(datamap, consumed_callback);// DS3D datarender would stop qutomatically when Gstpipeline is stopped.// But in the case if user want to stop it early or manually.// Obtain DS3D custom datarender and stop manually.c=datarender.stop();A customdatarendermust havetype:ds3d::datarender. It is created by explicit call ofNvDs3D_CreateDataRenderSink(sinkConfig,renderSink,start)with the full compoment YAML content. During this call, thecustom_lib_pathis loaded and a specific data loader is created viacustom_create_function. AGstAppsinkobject is also created intorenderSink.gstElement.GstAppsinkmanages theds3d::datarenderdataflows. Thisds3d::datarendercomponent could be  automatically started by thegst-pipeline, or manually by the application call.GuardDataRenderdatarender=renderSink.customProcessor;ErrCodec=datarender.start();To stop thedatarender, you can setGstAppsinkstates toGST_STATE_READY, or stop manually.
.. code-block:: textGuardDataRender datarender = renderSink.customProcessor;
ErrCode c = datarender.stop();GuardDataRenderprovides safe access toabidatarender. Once it’s created, it will maintain the reference pointer to datarender.prerollis called only once to initialize some resources.Implement a DS3D Custom Datarender#Examples:#include<ds3d/common/impl/impl_datarender.h>classTestFakeDataRender:publicimpl::BaseImplDataRender{public:TestFakeDataRender()=default;protected:ErrCodestartImpl(conststd::string&content,conststd::string&path)override{setInputCaps("ds3d/datamap");returnErrCode::kGood;}ErrCodeprerollImpl(GuardDataMapdatamap)override{returnErrCode::kGood;}ErrCoderenderImpl(GuardDataMapdatamap,OnGuardDataCBImpldataDoneCb)override{DS_ASSERT(datamap);emitError(ErrCode::kGood,"data rendered");dataDoneCb(ErrCode::kGood,datamap);returnErrCode::kGood;}ErrCodeflushImpl()override{returnErrCode::kGood;}ErrCodestopImpl()override{returnErrCode::kGood;}};DS3D_EXTERN_C_BEGINDS3D_EXPORT_APIabiRefdatarender*createTestFakedatarender(){returnNewAbiRef<abiDataRender>(newTestFakeDataRender());}DS3D_EXTERN_C_ENDAs shown in the example above, you’ll need to derivedatarenderfrom theds3d::impl::BaseImplDataRenderclass, and implement interfaces for the following:ErrCodestartImpl(conststd::string&content,conststd::string&path)override;ErrCodeprerollImpl(GuardDataMapdatamap)override;ErrCoderenderImpl(GuardDataMapdatamap,OnGuardDataCBImpldataDoneCb)override;ErrCodestopImpl()override;ErrCodeflushImpl()override;To load this custom lib throughNvDs3D_CreateDataRenderSink, you’ll also need to export a specific symbolcreateTestFakedatarender.Custom Libs Configuration Specifications#Components Common Configuration Specifications#ds3d common configuration specifications#PropertyMeaningType and RangeExampletypeCustom processor typeString, [ds3d::dataloader, ds3d::datafilter, ds3d::datarender]type: ds3d::dataloadernameIndicate user-defined component nameStringname: depthloaderin_capsIndicate Gst sink caps for the componentStringin_caps: ds3d/datamapout_capsIndicate Gst sink caps for the componentStringout_caps: ds3d/datamapcustom_lib_pathIndicate custom lib pathStringcustom_lib_path: libnvds_3d_gl_datarender.socustom_create_functionIndicate custom function to create the specific ds3d processing componentStringcustom_create_function: createPointCloudDataRenderconfig_bodyIndicate YAML specific content for the custom comonentStringconfig_body:in_streams: [color, depth]
max_points: 407040These custom libs are part of DeepStream release package.Supported DS3D Custom Process libraries#DS3D custom libs#DS3D Process TypeFunctionalityDS3D custom libraryDS3D Creating Instance FunctionDescriptiondataloaderlidar-file-readerlibnvds_lidarfileread.socreateLidarFileLoaderLidar file data reader library, see details inCustom Dataloader libnvds_lidarfileread Configuration Specificationsdataloaderrealsense camera depth/image capturelibnvds_3d_dataloader_realsense.socreateRealsenseDataloaderRealSense Camera capture dataloader library, see details inCustom Dataloader libnvds_3d_dataloader_realsense Configuration Specificationsdatafiltermulti sensor triton inference liblibnvds_tritoninferfilter.socreateLidarInferenceFilterMulti-modal sensor triton inference library, see details inlibnvds_tritoninferfilter Configuration Specificationsdatafilterdata_alignmentlibnvds_3d_alignment_datafilter.socreateLidarAlignmentFilterlidar/camera Sensor Intrinsic and Extrinsic parameters and alignment, see details inCustom ds3d::datafilter library: libnvds_3d_alignment_datafilter.sodatafilterlidar_data_preprocesslibnvds_3d_lidar_preprocess_datafilter.socreateLidarPreprocessFilterlidar data voxel processing, see details inCustom Datafilter libnvds_3d_lidar_preprocess_datafilter Specificationsdatafilterdepth-to-point-coundlibnvds_3d_depth2point_datafilter.socreateDepth2PointFilterConvert Image Depth data into 3D Point Cloud data, see details inCustom datafilter libnvds_3d_depth2point_datafilter Configuration Specificationsdatabridgebridge 2D into DS3Dlibnvds_3d_video_databridge.socreateVideoBridge2d3dConvert DeepStream 2D batchmeta and surface intods3d::datamap, see details inConfiguration filedatamixermixer for video and lidar/radarlibnvds_3d_multisensor_mixer.socreateMultiSensorMixerCombines video data (2D) and LiDAR data (3D) into a singleds3d::datamap, see details inConfiguration filedatarender3D multiview scene renderlibnvds_3d_gles_ensemble_render.soNvDs3D_CreateGlesEnsembleRenderRenders a 3D multi-view scene using GLES with with various elements (textures, LiDAR points, bounding boxes) insideds3d::datamap, see details inCustom datarender libnvds_3d_gles_ensemble_render Configuration Specificationsdatarender3D point-cloud data render with texturelibnvds_3d_gl_datarender.socreatePointCloudDataRenderRenders 3D(Scene construction) PointCould(XYZ) data with RGBA color textures insideds3d::datamap, see details inCustom datarender libnvds_3d_gl_datarender Configuration Specificationsdatarender3D lidar(XYZI/XYZ) data renderlibnvds_3d_gl_datarender.socreateLidarDataRenderRenders 3D Lidar(XYZI/XYZ) data insideds3d::datamap, see details inCustom datarender libnvds_3d_gl_datarender Configuration Specificationsdatarenderdepth image 2D renderlibnvds_3d_gl_datarender.socreateDepthStreamDataRenderRenders 2D depth and Camera RGBA data insideds3d::datamap, see details inCustom datarender libnvds_3d_gl_datarender Configuration Specificationslibnvds_tritoninferfilter Configuration Specifications#Multi-modal tensors Triton inference with key-value pairs inds3d::datamap, Supports user defined custom preprocess and postprocess.Configuration for multi-modal triton inference Header:name: multimodal_triton_infer
type: ds3d::datafilter
in_caps: ds3d/datamap
out_caps: ds3d/datamap
custom_lib_path: libnvds_tritoninferfilter.so
custom_create_function: createLidarInferenceFilterConfig body specificationslibnvds_tritoninferfilterconfig_bodyfields#PropertyMeaningType and RangeExamplein_streamswhich data type will be processedList of String, Optionalin_streams: [lidar]gpu_idGPU device IDInteger, default value:０gpu_id: 0config_filenvinferserver(triton) low level lib config file, supports gRPC and CAPI,
see more detailsLow Level libnvds_infer_server.so Configuration File SpecificationsString of Pathconfig_file: model_config_files/config_triton_bev_fusion_infer_grpc.pbtxtmem_pool_sizeSize of the input tensor poolIntegermem_pool_size: 8model_inputsmodel ‘s input layers information, If there is no custom_preprocess defined, inferencefilter would forward the key-value frames fromds3d::datamapto triton’s input tensorList of Dictname: input_image_0datatype: UINT8
shape: [1, 900, 1600, 4]
from: DS3D::ColorFrame_0+1
is_2d_frame: trueinput_tensor_mem_typeinput tensor memory type after preprocessString:[GpuCuda CpuCuda]input_tensor_mem_type: GpuCudacustom_preprocess_lib_pathcustom preprocessing library pathStringcustom_preprocess_lib_path: /opt/nvidia/deepstream/deepstream/lib/libnvds_lidar_custom_preprocess_impl.socustom_preprocess_func_namecustomized preprocessing function nameStringcustom_preprocess_func_name: CreateInferServerCustomPreprocesspostprocessUser defined postprocessing informationDictpostprocess:score_threshold: 0.5labelsUser defined labels for custom postprocessList of Dictlabels:car:color: [255, 158, 0]truck:color: [255, 99, 71]model_inputshas all input layers information. If there is custom preprocess function/lib specfied inside config body. The lib would searchfromkeyname of the inputds3d::datamap, and forward the frame/tensor data into Triton server’s input tensors. Thefromkeyname must be a frame, 2D-frame or tensor inside theds3d::datamapConfiguration Specifications of themodel_inputsitems of listmodel_inputs#PropertyDescriptionType and RangeExamplenameModel’s input tensor nameStringname: input_image_0datatypeModel’s input data typeString values in [FP32, FP16, INT8, INT32, INT16, UINT8, UINT16, UINT32, FP64, INT64, UINT64, BYTES, BOOL]datatype: FP32shapeModel’s input tensor shapeList of Integershape: [1, 900, 1600, 4]fromThe keyname of the inputds3d::datamap, the value must be a frame/2D-frame/tensor. If custom_preprocess is not existing, the frame would be forwarded into Triton’s input tensors directly.Stringfrom: DS3D::ColorFrame_5is_2d_frameIndicate thefrominside ofds3d::datamapis a 2D frame.Boolis_2d_frame: trueCustom preprocess before triton inferenceIfcustom_preprocess_lib_pathandcustom_preprocess_func_nameare specified, Custom processing will be loaded and parse the config body and get all common and user defined information. then process each inputds3d::datamapand generatebatchArrayfor triton inference inputs.Users can derive interfaceIInferCustomPreprocessorfromsources/includes/ds3d/common/hpp/lidar_custom_process.hppSee examples insources/libs/ds3d/inference_custom_lib/ds3d_v2x_infer_custom_preprocess/nvinferserver_custom_preprocess.cpp#include<ds3d/common/hpp/datamap.hpp>#include<ds3d/common/hpp/frame.hpp>#include<ds3d/common/hpp/lidar_custom_process.hpp>usingnamespaceds3d;usingnamespacenvdsinferserver;classNvInferServerCustomPreProcess:publicIInferCustomPreprocessor{public:// process key-values from datamap and generate into model inputs batchArray.NvDsInferStatuspreproc(GuardDataMap&datamap,SharedIBatchArraybatchArray,cudaStream_tstream)override{...}};extern"C"{IInferCustomPreprocessor*CreateInferServerCustomPreprocess(){returnnewNvInferServerCustomPreProcess();}}Custom postprocess after triton inferencePostprocessing is quite specific for each model. You’ll need to implement your own postprocessing functions based on inference output tensors results.
Custom postprocess libs and functions are specfied from nvdsinferserver’s config. for example inapps/sample_apps/deepstream-3d-lidar-sensor-fusion/model_config_files/config_triton_bev_fusion_infer_grpc.pbtxtinfer_config {
  backend {
    triton {
      model_name: "bevfusion"
      grpc {...}
  } }
  extra {
    output_buffer_pool_size: 4
    # specify custom postprocess function
    custom_process_funcion: "Nvds3d_CreateLidarDetectionPostprocess"
  }
  custom_lib {
    # specify custom postprocess library
    path: "libnvds_3d_infer_postprocess_lidar_detection.so"
  }
}An example of custom postprocess implementation is provided here:sources/libs/ds3d/inference_custom_lib/ds3d_lidar_detection_postprocess/ds3d_infer_postprocess_lidar_detection.cpp#include"infer_custom_process.h"#include<ds3d/common/hpp/frame.hpp>#include<ds3d/common/hpp/datamap.hpp>usingnamespaceds3d;usingnamespacenvdsinferserver;classDS3DTritonLidarInferCustomPostProcess:publicIInferCustomProcessor{public:// process key-values from datamap and generate into model inputs batchArray.NvDsInferStatusinferenceDone(constIBatchArray*batchArray,constIOptions*inOptions)override{...// get ``ds3d::datamap`` from ``inOptions``abiRefDataMap*refDataMap=nullptr;if(inOptions->hasValue(kLidarRefDataMap)){INFER_ASSERT(inOptions->getObj(kLidarRefDataMap,refDataMap)==NVDSINFER_SUCCESS);}GuardDataMapdataMap(*refDataMap);...// parsing output tensors from batchArrayTensorMapoutTensors;for(uint32_ti=0;i<batchArray->getSize();++i){autobuf=batchArray->getSafeBuf(i);outTensors[buf->getBufDesc().name]=buf;}std::vector<Lidar3DBbox>bboxes;ret=parseLidar3Dbbox(outTensors,bboxes);// warp data into ds3d frame ``bboxFrame``size_tbufBytes=sizeof(Lidar3DBbox)*bboxes.size();void*bufBase=(void*)bboxes.data();Shapeshape{3,{1,(int)bboxes.size(),sizeof(Lidar3DBbox)}};FrameGuardbboxFrame=impl::WrapFrame<uint8_t,FrameType::kCustom>(bufBase,bufBytes,shape,MemType::kCpu,0,[outdata=std::move(bboxes)](void*){});// add key-value fram into ds3d::datamapErrCodecode=dataMap.setGuardData(_3dBboxKey,bboxFrame);...returnret;}};extern"C"{IInferCustomProcessor*Nvds3d_CreateLidarDetectionPostprocess(){returnnewDS3DTritonLidarInferCustomPostProcess();}}Custom Datafilter libnvds_3d_alignment_datafilter Specifications#Data alignment for lidar and video data can be done using a custom library provided with DeepStreamSDK.More details on this is here:Custom ds3d::datafilter library: libnvds_3d_alignment_datafilter.so.Custom Datafilter libnvds_3d_lidar_preprocess_datafilter Specifications#LiDAR data preprocess into voxel data format before V2X model sensor fusion inference.
Source files located at/opt/nvidia/deepstream/deepstream/sources/libs/ds3d/datafilter/lidar_preprocessConfiguration for Lidar data preprocessds3d::datafilterHeader:name: lidarpreprocess
type: ds3d::datafilter
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_lidar_preprocess_datafilter.so
custom_create_function: createLidarPreprocessFilterConfig Body SpecificationsFor example:config_body:
mem_pool_size: 4
filter_input_datamap_key: DS3D::LidarXYZI_0
model_inputs:
- name: feats
  datatype: FP16
  shape: [4, 8000, 10, 9]
- name: coords
  datatype: INT32
  shape: [4, 8000, 4]
- name: N
  datatype: INT32
  shape: [4, 1]
gpu_id: 0
input_tensor_mem_type: GpuCuda
lidar_data_from: [DS3D::LidarXYZI_0, DS3D::LidarXYZI_1, DS3D::LidarXYZI_2, DS3D::LidarXYZI_3]
output_features_tensor_key: DS3D::LidarFeatureTensor
output_coords_tensor_key: DS3D::LidarCoordTensor
output_num_tensor_key: DS3D::LidarPointNumTensorDS3D libnvds_3d_lidar_preprocess_datafilter custom libs#PropertyDescriptionType and RangeExamplemem_pool_sizememory buffer pool sizeIntegermem_pool_size: 4filter_input_datamap_keySpecify input lidar data key nameStringfilter_input_datamap_key: DS3D::LidarXYZI_0model_inputsSpecify model input layers infoDictsee exmaple in deepstrem-3d-lidar-sensor-fusion/ds3d_lidar_video_sensor_v2xfusion.ymlgpu_idSpecify GPU IDIntegergpu_id: 0input_tensor_mem_typeSpecify model input tensors memory typeString, select value from [GpuCuda, CpuCuda]input_tensor_mem_type: GpuCudalidar_data_fromSpecify lidar data key nameList of Stringlidar_data_from: [DS3D::LidarXYZI_0]output_features_tensor_keySpecify output lidar feature tensor key nameStringDS3D::LidarFeatureTensoroutput_coords_tensor_keySpecify output lidar coordinate tensor key nameStringoutput_coords_tensor_key: DS3D::LidarCoordTensoroutput_num_tensor_keySpecify keyname of numbers of ldiar data into tensorStringoutput_num_tensor_key: DS3D::LidarPointNumTensorCustom Dataloader libnvds_lidarfileread Configuration Specifications#The lib reads lidar data file frame by frame, it creates a newds3d::datamapper frame and deliver to next compoment.
Source files located at/opt/nvidia/deepstream/deepstream/sources/libs/ds3d/dataloader/lidarsourceConfiguration for Lidar file readerds3d::dataloaderHeader:name: ds3d_lidar_file_source
type: ds3d::dataloader
out_caps: ds3d/datamap
custom_lib_path: libnvds_lidarfileread.so
custom_create_function: createLidarFileLoaderConfig Body SpecificationsFor example:config_body:
  data_config_file: lidar_nuscene_data_list.yaml
  points_num: 242180
  fixed_points_num: True
  lidar_datatype: FP32
  mem_type: gpu
  gpu_id: 0
  mem_pool_size: 6
  element_size: 4
  output_datamap_key: DS3D::LidarXYZI
  file_loop: TrueDS3D libnvds_lidarfileread custom libs#PropertyDescriptionType and RangeExampledata_config_filelidar data list file pathPath String, or List of Path Stringdata_config_file: lidar_data_list.yamlsource_idSpecify the unique source id of the loader instanceIntegersource_id: 0points_numSpecify point number of each frameIntegerpoints_num: 70000fixed_points_numIndicate the point number is always same aspoints_numBoolfixed_points_num: Falselidar_datatypeSpecify Lidar data typeString, Only FP32 supported for now.lidar_datatype: FP32mem_typeSpecify memory type of process data, supports [cpu, gpu]String, [cpu, gpu]mem_type: gpumem_pool_sizeSpecify buffer pool size allocated for framesIntegermem_pool_size: 16gpu_idSpecify GPU ID in the case ofmem_type:gpuIntegergpu_id: 0element_sizeSpecify how manay elements will be read per each point. 3, means XYZ, 4, means XYZI.Integerelement_size: 4element_strideSpecify element stride between 2 continous points. e.g. XYZI, stride:4, XYZIT,5Integerelement_stride: 4file_loopIndicate whether loop the file list without EOSBoolfile_loop: Trueoutput_datamap_keySpecify output frame keyname into theds3d::datamapString or List of Stringoutput_datamap_key: DS3D::LidarXYZI_0lidar data config fileThe lib reads frames fromdata_config_filewhich is a seperate file containers multiple lidar files. each lidar file is a single lidar frame file which are listed inside ofsource-list. Each item’s keyname is the timestamp(millisecond) of the lidar frame.An example ofdata_config_file.source-list:
  - 0: /opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-3d-lidar-sensor-fusion/data/nuscene/LIDAR_TOP/000000-LIDAR_TOP.bin
  - 50: /opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-3d-lidar-sensor-fusion/data/nuscene/LIDAR_TOP/000001-LIDAR_TOP.bin
  - 100: /opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-3d-lidar-sensor-fusion/data/nuscene/LIDAR_TOP/000002-LIDAR_TOP.binCustom Dataloader libnvds_3d_dataloader_realsense Configuration Specifications#Configuration forRealsenseDataloaderHeader:name: realsense_dataloader
type: ds3d::dataloader
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_dataloader_realsense.so
custom_create_function: createRealsenseDataloaderlibnvds_3d_dataloader_realsense.sorequires you to installlibrealsense2SDK. For x86, follow the instructions fromIntelRealSense/librealsense.
For Jetson platform, follow the instructions fromIntelRealSense/librealsense.libnvds_3d_dataloader_realsenseconfig_bodyfields#PropertyMeaningType and RangeExamplestreamsSpecify which streams to enableList[String],  select from [color, depth]streams: [color, depth]aligned_image_to_depthIndicate whether color image is aligned to depthBooleanaligned_image_to_depth: FalseCustom datafilter libnvds_3d_depth2point_datafilter Configuration Specifications#Convert 2D depth data into 3D point-cloud(XYZ) data intods3d::datamapConfiguration for Depth to Points Header:name: depth2points
type: ds3d::datafilter
in_caps: ds3d/datamap
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_depth2point_datafilter.so
custom_create_function: createDepth2PointFilterlibnvds_3d_depth2point_datafilterconfig_bodyfields#PropertyMeaningType and RangeExamplestreamsSpecify which streams to enableList[String],  select from [color, depth]streams: [color, depth]max_pointsIndicate maximum 3d points to allocateUint32max_points: 407040mem_pool_sizeIndicate max buffer pool sizeUint32mem_pool_size: 8Custom datarender libnvds_3d_gles_ensemble_render Configuration Specifications#Renders 3D scene using OpenGL ES (GLES) with various elements (textures, LiDAR points, bounding boxes) within a single window, allowing for flexible layout customization. Users can split the windows into multiple views, and project each tensor data or frame fromds3d::datamapinto a seperate view or into multiple views at the same time.
It could also support overlay if multi frames rendered into a single view positon overlap, it depends on the render graph order.Configuration Headername: ds3d_sensor_fusion_render
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_3d_gles_ensemble_render.so
custom_create_function: NvDs3D_CreateGlesEnsembleRenderConfiguration BodyAn example of a multi-view config withrender_graph. There are 2 views rendered with different frames inside the sameds3d::datamap. The 2D color image is rendered bytexture3d_renderinto view area[0,0,640,360]; The Lidar data is rendered bylidar3d_renderinto view area[640,0,1280,360].config_body:
  window_width: 1280 # window size
  window_height: 360 # window size
  color_clear: true
  window_title: DS3D-Lidar-6-Cameras-BEVFusion
  render_graph:
    - texture3d_render: # 2D texture view
        layout: [0, 0, 640, 360] # layout [x0, y0, x1, y1]
        max_vertex_num: 6
        color_clear: false
        texture_frame_key: DS3D::ColorFrame_2 # image data key
    - lidar3d_render: # lidar top view
        layout: [640, 0, 1280, 360] # layout [x0, y0, x1, y1]
        color_clear: false
        view_position: [0, 0, 30]
        view_target: [0, 0, 0]
        view_up: [0, 1, 0]
        lidar_color: [0, 0, 255]
        lidar_data_key: DS3D::LidarXYZI
        lidar_bbox_key: DS3D::Lidar3DBboxRawData
        element_size: 4libnvds_3d_gles_ensemble_renderconfig_bodyfields#PropertyMeaningType and RangeExamplewindow_titleSpecify window titlestringwindow_title: DS3D-Lidar-6-Cameras-BEVFusionwindow_widthSpecify window widthuint32window_width: 1920window_heightSpecify window heightuint32window_height: 1080color_clearSpecify whether to clear up the whole window when new frame arriveboolcolor_clear: truerender_graphSpecify a list of multiple renders in different viewsList[Dict]render_graph:
 - texture3d_render:
    layout: [0, 0, 640, 360]
    color_clear: false
    texture_frame_key: DS3D::ColorFrame
 - lidar3d_render:
    layout:  [640, 0, 1280, 360]
    color_clear: false
    lidar_data_key: DS3D::LidarXYZIRender graphrender_graphIt supports 2 different modes of viewstexture3d_render, it renders 2D image data into a specified view area.lidar3d_render, it renders lidar data and 3D bbox data into a specified view area.Each mode could be configured multiple times in the samerender_graph. Multiple camera data inside a singleds3d::datamapcould be configured into different view area. Similarly, multiple lidar data insdie the sameds3d::datamapcould also be configured at different viewpoint(topview, front-view, side-view) into different view area.Configuration Specifications oftexture3d_renderlibnvds_3d_gles_ensemble_rendertexture3d_renderfields#PropertyMeaningType and RangeExamplelayoutSpecify the view location for [x0, y0, x1, y1]List[Float]layout: [0, 0, 640, 360]
x0 = 0;
y0 = 0;
x1 = 640;
y1 = 360;color_clearIndicate whether to clear up this view before new frame came.boolcolor_clear: falsetexture_frame_keySpecify texture image keyname fromds3d::datamapstringtexture_frame_key: DS3D::ColorFrame_1+1max_vertex_numSpecify vertex_num used for the texture drawing, default value 6uint32max_vertex_num: 6texture_vetex_keySpecify 3D vertex key name fromds3d::datamap, it’s used for the texture drawing, there are 6 values by default.stringtexture_vetex_key: DS3D::TextureVertexKeytexture_coord_keySpecify texture coordinate key name fromds3d::datamap, it’s used for the texture drawing, there are 6 values by default.stringtexture_coord_key: DS3D::TextureCoordKeyConfiguration Specifications oflidar3d_renderlibnvds_3d_gles_ensemble_renderlidar3d_renderfields#PropertyMeaningType and RangeExamplelayoutSpecify the view location for [x0, y0, x1, y1]List[Float]layout: [0, 0, 640, 360]
x0 = 0;
y0 = 0;
x1 = 640;
y1 = 360;color_clearIndicate whether to clear up this view before new frame came.boolcolor_clear: falselidar_colorSpecify lidar data color RGBlist[uint8]lidar_color: [0, 0, 255]lidar_data_keySpecify lidar data keyname fromds3d::datamapstringlidar_data_key: DS3D::LidarXYZI+0element_sizeSpecify lidar data element size. choose from [3, 4], default value 4 is for xyzi. value 3 is for xyz.uint32element_size: 4lidar_bbox_keySpecify 3D detection bounding-box key name fromds3d::datamapstringlidar_bbox_key: DS3D::Lidar3DBboxRawDataproject_lidar_to_imageIndicate whether need project lidar data and bounding-box into camera image, default value: falseboolproject_lidar_to_image: falseintrinsics_mat_keySpecify camera intrinsics matrix key name fromds3d::datamap,  It’s needed when project_lidar_to_image: trueintrinsics_mat_key: DS3D::Cam2_IntrinsicMatrixextrinsics_mat_keySpecify lidar extrinsics matrix key name fromds3d::datamapextrinsics_mat_key: DS3D::LidarToCam2_ExtrinsicMatriximage_widthSpecify original camera intrinsic image width, this is needed when project_lidar_to_image: trueimage_width: 1600image_heightSpecify original camera intrinsic image height, this is needed when project_lidar_to_image: trueimage_height: 900view_positionSpecify view position [x, y, z]coordinatesList[Float]view_position: [0, 0, -1]view_targetSpecify view target [x, y, z]coordinatesList[Float]view_target: [0, 0, 1]view_upSpecify view up direction [x, y, z]coordinatesList[Float]view_up: [0, -1.0, 0]perspective_nearSpecify perspective projection near planeFloatperspective_near: 0.1perspective_farSpecify perspective projection far planeFloatperspective_far: 10.0perspective_fovSpecify perspective projection field of view,  degree angleFloatperspective_fov: 40.0perspective_ratioSpecify perspective ratio for width/height. default 0.0f means view-width/view-heightFloatperspective_ratio: 0.0enable_labelIndicate whether label text render enabled. default value: falseboolenable_label: trueCustom datarender libnvds_3d_gl_datarender Configuration Specifications#Configuration Common header forlibnvds_3d_gl_datarender:name: depth-point-render
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_3d_gl_datarender.soConfiguration Body for Common Part:libnvds_3d_gl_datarenderconfig_bodycommon fields#PropertyMeaningType and RangeExampletitleSpecify window titleStringtitle: ds3d-point-cloud-teststreamsIndicate which streams to render. depth render must have [depth], 3D points render must have [points]List[String],  select from [color, depth, points]streams: [color, depth]widthSpecify window widthUINT32width: 1280heightSpecify window heightUINT32height: 720blockIndicate rendering thread as block modeBooleanblock: TrueConfiguration Header for Point Cloud Render:name: point-3D-render
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_3d_gl_datarender.so
custom_create_function: createPointCloudDataRender # specific function for 3D point renderingConfiguration Header for Lidar data Render:name: lidar-data-render
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_3d_gl_datarender.so
custom_create_function: createLidarDataRender # specific function for Lidar point cloud renderingConfiguration Body for 3D Point Cloud and Lidar Render Part:For more details on 3D coordinate system, refer tohttps://learnopengl.com/Getting-started/Coordinate-Systems.
To know the value meanings forview_position,view_targetandview_up,refer to  thegluLookAthere:https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/gluLookAt.xml.
To know the value meanings fornear,farandfov, refer to thegluPerspectivehere:https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/gluPerspective.xml.libnvds_3d_gl_datarender Point Cloud Renderconfig_bodyFields#PropertyMeaningType and RangeExampleview_positionSpecify view position [x, y, z]coordinatesList[Float]view_position: [0, 0, -1]view_targetSpecify view target [x, y, z]coordinatesList[Float]view_target: [0, 0, 1]view_upSpecify view up direction [x, y, z]coordinatesList[Float]view_up: [0, -1.0, 0]nearSpecify perspective projection near planeFloatnear: 0.01farSpecify perspective projection far planeFloatfar: 10.0fovSpecify perspective projection field of view,  degree angleFloatfov: 40.0coord_y_oppositeSpecify texture map V direction, Realsense coordinates is different from GLES default coordinatesBooleancoord_y_opposite: Falsepositive_z_onlySpecify whether display negtive depth valuesBooleanpositive_z_only: FalseConfiguration Body for Lidar Render Specific Part:libnvds_3d_gl_datarender Lidar Render extraconfig_bodyFields#PropertyMeaningType and RangeExampleview_positionSpecify view position [x, y, z]coordinatesList[Float]view_position: [0, 0, -1]view_targetSpecify view target [x, y, z]coordinatesList[Float]view_target: [0, 0, 1]view_upSpecify view up direction [x, y, z]coordinatesList[Float]view_up: [0, -1.0, 0]nearSpecify perspective projection near planeFloatnear: 0.01farSpecify perspective projection far planeFloatfar: 10.0fovSpecify perspective projection field of view,  degree angleFloatfov: 40.0lidar_colorSpecify lidar data color for displayList[Uint32]lidar_color: [0, 255, 0]element_sizeSpecify lidar data element size. e.g. 4 for XYZI or 3 for XYZUint32element_size: 4lidar_data_keySpecify lidar data frame in datamap, default value is DS3D::LidarXYZIStringlidar_data_key: DS3D::LidarXYZIlidar_bbox_keySpecify lidar 3D bounding box data in datamap, default value is DS3D::Lidar3DBboxRawDataStringlidar_bbox_key: DS3D::Lidar3DBboxRawDataConfiguration Header for Depth and Color 2D Render:name: depth-2D-render
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_3d_gl_datarender.so
custom_create_function: createDepthStreamDataRender # specific function for 2D depth renderingConfiguration Body for Depth and Color 2D Specific Part:libnvds_3d_gl_datarender 2D Depth Renderconfig_bodyFields#PropertyMeaningType and RangeExamplemin_depthSpecify minimum depth value. other values less that it will be removed in renderingFloatmin_depth: 0.3max_depthSpecify maximum depth value. other values less that it will be removed in renderingFloatmax_depth: 2.0min_depth_colorSpecify minimum depth rendering color in [R, G, B]List[Uint32]min_depth_color: [255, 128, 0]max_depth_colorSpecify maximum depth rendering color in [R, G, B]Floatmax_depth_color: [0, 128, 255]libnvds_3d_depth_datasource Depth file source Specific Configuration Specifications#Configuration header:name: depthfilesource
type: ds3d::dataloader
out_caps: ds3d/datamap, framerate=30/1
custom_lib_path: libnvds_3d_depth_datasource.so
custom_create_function: createDepthColorLoaderConfiguration body:libnvds_3d_depth_datasource Depth file sourceconfig_bodyFields#PropertyMeaningType and RangeExampledepth_sourceSpecify file path for depth sourceStringdepth_source: depth_uint16_640x480.bincolor_sourceSpecify file path for color image sourceStringcolor_source: color_rgba_1920x1080.bindepth_scaleIndicate depth unit in meters per each depth valueFloatdepth_scale: 0.0010depth_datatypeIndicate depth datatype, only [uint16] is supported for this versionString, Values must be uint16depth_datatype: uint16depth_sizeIndicate depth resolutions in [width, height]List[Uint32], must be [width, height]depth_size: [640, 480]colorIndicate color format. onlyrgbais supportedString. Value must be rgbacolor: rgbacolor_sizeIndicate color resolutions in [width, height]List[Uint32], must be [width, height]color_size: [1920, 1080]depth_intrinsicIndicate depth sensor intrinsic parameter groupsIntrinsic Configuration Groupdepth_intrinsic:width: 848
height: 480
centerX: 424.06073
centerY: 237.75032
fx: 422.513062
fy: 422.513062color_intrinsicIndicate color sensor intrinsic parameter groupsIntrinsic Configuration Groupcolor_intrinsic:width: 1920
height: 1080
centerX: 964.288086
centerY: 533.287354
fx: 1358.21423
fy: 1358.2533depth_to_color_extrinsicIndicate extrinsic parameters from depth sensor to color sensorExtrinsic Configuration Groupdepth_to_color_extrinsic:rotation: [1, -0.0068, 0.0010, 0.0068, 1, 0, -0.0010, 0, 1]
translation: [0.01481, -0.0001, 0.0002]Configuration Body for Intrinsic Parameters :libnvds_3d_depth_datasource Intrinsic Parameters in Depth file sourceconfig_bodyFields#PropertyMeaningType and RangeExamplewidthSpecify sensor width in pixelsUint32width: 848heightSpecify sensor height in pixelsUint32height: 480centerXSpecify coordinate axis position in pixels in horizontal directionFloatcenterX: 424.06centerYSpecify coordinate axis position in pixels in vertical directionFloatcenterY: 533.28fxSpecify focal length in pixels in X directionFloatfx: 1358.21fySpecify focal length in pixels in Y directionFloatfy: 1358.25Configuration Body for Extrinsic Parameters:libnvds_3d_depth_datasource Extrinsic Parameters in Depth file sourceconfig_bodyFields#PropertyMeaningType and RangeExamplerotationSpecify an extrinsic 3x3 matrix for rotation. Values in Column-major orderList[Float], Values in Column-major orderrotation: [1, -0.0068, 0.0010, 0.0068, 1, 0, -0.0010, 0, 1]translationSpecify an extrinsic 3x1 matrix for translation. Values in Column-major orderList[Float], Values in Column-major ordertranslation: [0.01481, -0.0001, 0.0002]previousTAO Toolkit Integration with DeepStreamnextPerformanceOn this pageDS3D Application ExamplesDS3D data formatds3d/datamapDS3D DataMap interoperate with GstBufferds3d::dataloader- Load Custom Lib for Data CaptureLoad and Manage DS3D DataloaderDS3D Dataloader in DeepStream User ApplicationImplement a DS3D Custom Dataloaderds3d::databridge- Loads Custom Lib for data conversion to and from DS3D.ds3d::datafilter-  DS3D Custom DataFilterCreate And Manage DS3D Datafilter in DeepStream AppImplement a Custom DS3D Datafilterds3d::datarender- Loads DS3D Custom DataRenderLoad And Manage DS3D DatarenderImplement a DS3D Custom DatarenderCustom Libs Configuration SpecificationsComponents Common Configuration SpecificationsSupported DS3D Custom Process librarieslibnvds_tritoninferfilter Configuration SpecificationsCustom Datafilter libnvds_3d_alignment_datafilter SpecificationsCustom Datafilter libnvds_3d_lidar_preprocess_datafilter SpecificationsCustom Dataloader libnvds_lidarfileread Configuration SpecificationsCustom Dataloader libnvds_3d_dataloader_realsense Configuration SpecificationsCustom datafilter libnvds_3d_depth2point_datafilter Configuration SpecificationsCustom datarender libnvds_3d_gles_ensemble_render Configuration SpecificationsCustom datarender libnvds_3d_gl_datarender Configuration Specificationslibnvds_3d_depth_datasource Depth file source Specific Configuration SpecificationsPrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.