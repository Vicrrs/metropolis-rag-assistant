Smart Video Record — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formSmart Video RecordSmart Video Record#Smart video record is used for event (local or cloud) based recording of original data feed. Only the data feed with events of importance is recorded instead of always saving the whole feed. This recording happens in parallel to the inference pipeline running over the feed.
A video cache is maintained so that recorded video has frames both before and after the event is generated. The size of the video cache can be configured per use case.In smart record, encoded frames are cached to save on CPU memory. Based on the event, these cached frames are encapsulated under the chosen container to generate the recorded video. This means, the recording cannot be started until we have an Iframe. The first frame in the cache may not be an Iframe, so, some frames from the cache are dropped to fulfil this condition. This causes the duration of the generated video to be less than the value specified.Below diagram shows the smart record architecture:From DeepStream 6.0, Smart Record also supports audio. It uses same caching parameters and implementation as video. To enable audio, a GStreamer element producing encoded audio bitstream must be linked to theasinkpad of the smart record bin. Both audio and video will be recorded to the same containerized file. Refer to thedeepstream-testsrsample application for more details on usage.Smart Video Record Module APIs#This module provides the following APIs. See thegst-nvdssr.hheader file for more details.NvDsSRStatusNvDsSRCreate(NvDsSRContext**ctx,NvDsSRInitParams*params);This function creates the instance of smart record and returns the pointer to an allocatedNvDsSRContext. Theparamsstructure must be filled with initialization parameters required to create the instance.A callback function can be setup to get the information of recorded audio/video once recording stops.userDatareceived in that callback is the one which is passed duringNvDsSRStart().GstBinwhich is therecordbinofNvDsSRContextmust be added to the pipeline. It expects encoded frames which will bemuxedand saved to the file. Add this bin after the audio/video parser element in the pipeline.CallNvDsSRDestroy()to free resources allocated by this function.NvDsSRStatusNvDsSRStart(NvDsSRContext*ctx,NvDsSRSessionId*sessionId,guintstartTime,guintduration,gpointeruserData);This function starts writing the cached audio/video data to a file. It returns the session id which later can be used inNvDsSRStop()to stop the corresponding recording.HerestartTimespecifies the seconds before the current time anddurationspecifies the seconds after the start of recording.If current time ist1,content from t1 - startTime to t1 + durationwill be saved to file. Therefore, a total ofstartTime + duration secondsof data will be recorded. In case duration is set to zero, recording will be stopped afterdefaultDurationseconds set inNvDsSRCreate().Any data that is needed during callback function can be passed asuserData.NvDsSRStatusNvDsSRStop(NvDsSRContext*ctx,NvDsSRSessionIdsessionId);This function stops the previously started recording.NvDsSRStatusNvDsSRDestroy(NvDsSRContext*ctx);This function releases the resources previously allocated byNvDsSRCreate()See thedeepstream_source_bin.cfor more details on using this module.Smart Video Record Configurations#In existingdeepstream-test5-apponly RTSP sources are enabled for smart record. There are two ways in which smart record events can be generated – either through local events or through cloud messages. To enable smart record indeepstream-test5-appset the following under[sourceX]group:smart-record=<1/2>To enable smart record through only cloud messages, setsmart-record=1and configure[message-consumerX]group accordingly.
The following minimum json message from the server is expected to trigger theStart/Stopof smart record.{command:string// <start-recording / stop-recording>start:string// "2020-05-18T20:02:00.051Z"end:string// "2020-05-18T20:02:02.851Z",sensor:{id:string}}If you setsmart-record=2, this will enable smart record through cloud messages as well as local events with default configurations. That means smart recordStart/Stopevents are generated every 10 seconds through local events.
Following are the default values of configuration parameters:cachesize=30seconds,container=MP4,defaultduration=10seconds,interval=10seconds,fileprefix=Smart_Recordetc.Following fields can be used under[sourceX]groups to configure these parameters.smart-rec-cache=<valinseconds>Size of cache in seconds. This parameter will increase the overall memory usages of the application.smart-rec-duration=<valinseconds>Duration of recording.smart-rec-start-time=<valinseconds>Here, start time of recording is the number of seconds earlier to the current time to start the recording.
For example, if t0 is the current time and N is the start time in seconds that means recording will start from t0 – N. For it to work, the cache size must be greater than the N.smart-rec-default-duration=<valinseconds>In case a Stop event is not generated. This parameter will ensure the recording is stopped after a predefined default duration.Smart-rec-container=<0/1>MP4 and MKV containers are supported.smart-rec-interval=<valinseconds>This is the time interval in seconds for SR start / stop events generation.
In the deepstream-test5-app, to demonstrate the use case smart record Start / Stop events are generated every interval second.smart-rec-file-prefix=<filenameprefix>Prefix of file name for generated stream. By default, “Smart_Record” is the prefix in case this field is not set. For unique names every source must be provided with a unique prefix.smart-rec-dir-path=<pathofdirectorytosavethefile>Path of directory to save the recorded file. By default, the current directory is used.Recording also can be triggered by JSON messages received from the cloud. The message format is as follows:{command:string// <start-recording / stop-recording>start:string// "2020-05-18T20:02:00.051Z"end:string// "2020-05-18T20:02:02.851Z",sensor:{id:string}}Receiving and processing such messages from the cloud is demonstrated in thedeepstream-test5sample application. This is currently supported for Kafka. To activate this functionality, populate and enable the following block in the application configuration file:# Configure this group to enable cloud message consumer.[message-consumer0]enable=1proto-lib=/opt/nvidia/deepstream/deepstream/lib/libnvds_kafka_proto.soconn-str=<host>;<port>config-file=<brokerconfigfilee.g.cfg_kafka.txt>subscribe-topic-list=<topic1>;<topic2>;<topicN># Use this option if message has sensor name as id instead of index (0,1,2 etc.).#sensor-list-file=dstest5_msgconv_sample_config.txtWhile the application is running, use a Kafka broker to publish the above JSON messages on topics in the subscribe-topic-list to start and stop recording.NoteCurrently, there is no support for overlapping smart record.previousDeepStream-3D Multi-Modal V2XFusion SetupnextIoTOn this pageSmart Video Record Module APIsSmart Video Record ConfigurationsPrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.