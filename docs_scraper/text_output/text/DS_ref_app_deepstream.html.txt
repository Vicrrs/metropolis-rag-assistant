DeepStream Reference Application - deepstream-app — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formDeepStream...DeepStream Reference Application - deepstream-app#Application Architecture#The image below shows the architecture of the NVIDIA®DeepStream reference application.The DeepStream reference application is a GStreamer based solution and consists of set of GStreamer plugins encapsulating low-level APIs to form a complete graph. The reference application has capability to accept input from various sources like camera, RTSP input, encoded file input, and additionally supports multi stream/source capability. The list of GStreamer plugins implemented by NVIDIA and provided as a part of DeepStream SDK include:The Stream Muxer plugin (Gst-nvstreammux) to form a batch of buffers from multiple input sources.The Preprocess plugin (Gst-nvdspreprocess) for preprocessing on the pre-defined ROIs for primary inferencing.The NVIDIA TensorRT™ based plugin (Gst-nvinfer) for primary and secondary (attribute classification of primary objects) detection and classification respectively.The Multi-Object Tracker plugin (Gst-nvtracker) for object tracking with unique ID.The Multi Stream Tiler plugin (Gst-nvmultistreamtiler) for forming 2D array of frames.The Onscreen Display (OSD) plugin (Gst-nvdsosd) to draw shaded boxes, rectangles and text on the composited frame using the generated metadata.The Message Converter (Gst-nvmsgconv) and Message Broker (Gst-nvmsgbroker) plugins in combination to send analytics data to a server in the Cloud.Reference Application Configuration#The NVIDIA DeepStream SDK reference application uses one of the sample configuration files from thesamples/configs/deepstream-appdirectory in the DeepStream package to:Enable or disable componentsChange the properties or behavior of componentsCustomize other application configuration settings that are unrelated to the pipeline and its componentsThe configuration file uses a key file format, based on the freedesktop specifications at:https://specifications.freedesktop.org/desktop-entry-spec/latestExpected Output for the DeepStream Reference Application (deepstream-app)#The image below shows the expected output with preprocess plugin disabled:The image below shows the expected output with preprocess plugin enabled (Green bboxes are pre-defined ROIs):Configuration Groups#The application configuration is divided into groups of configurations for each component and application-specific component. The configuration groups are:Configuration Groups - deepstream app#GroupConfiguration GroupApplication GroupApplication configurations that are not related to a specific component.Tiled-display GroupTiled display in the application.Source GroupSource properties. There can be multiple sources. The groups must be named as: [source0], [source1] …Source-list and source-attr-all GroupsSource URI provided as a list. There can be multiple sources. The groups must be named as: [source-list] and [source-attr-all]Streammux GroupSpecify properties and modify behavior of the streammux component.Preprocess GroupSpecify properties and modify behavior of the preprocess component.Primary GIE and Secondary GIE GroupSpecify properties and modify behavior of the primary GIE.
Specify properties and modify behavior of the secondary GIE. The groups must be named as: [secondary-gie0], [secondary-gie1] …Tracker GroupSpecify properties and modify behavior of the object tracker.Message Converter GroupSpecify properties and modify behavior of the message converter component.Message Consumer GroupSpecify properties and modify behavior of message consumer components. The pipeline can contain multiple message consumer components. Groups must be named as [message-consumer0], [message-consumer1] …OSD GroupSpecify properties and modify the on-screen display (OSD) component that overlays text and rectangles on the frame.Sink GroupSpecify properties and modify behavior of sink components that represent outputs such as displays and files for rendering, encoding, and file saving. The pipeline can contain multiple sinks. Groups must be named as: [sink0], [sink1] …Tests GroupDiagnostics and debugging. This group is experimental.NvDs-analytics GroupSpecify nvdsanalytics plugin configuration file, and to add the plugin in the applicationApplication Group#The application group properties are:Application group#KeyMeaningType and ValueExamplePlatformsenable-perf-measurementIndicates whether the application performance measurement is enabled.Booleanenable-perf-measurement=1dGPU, Jetsonperf-measurement-interval-secThe interval, in seconds, at which the performance metrics are sampled and printed.Integer, >0perf-measurement-interval-sec=10dGPU, Jetsongie-kitti-output-dirPathname of an existing directory where the application stores primary detector output in a modified KITTI metadata format.Stringgie-kitti-output-dir=­/home/­ubuntu/­kitti_data/dGPU, Jetsonkitti-track-output-dirPathname of an existing directory where the application stores tracker output in a modified KITTI metadata format.Stringkitti-track-output-dir=­/home/­ubuntu/­kitti_data_tracker/dGPU, Jetsonreid-track-output-dirPathname of an existing directory where the application stores tracker’s Re-ID feature output. Each line’s first integer is object id, and the remaining floats are its feature vector.Stringreid-track-output-dir=­/home/­ubuntu/­reid_data_tracker/dGPU, Jetsonterminated-track-output-dirPathname of an existing directory where the application stores terminated tracker output in a modified KITTI metadata format.Stringkitti-track-output-dir=­/home/­ubuntu/­terminated_data_tracker/dGPU, Jetsonshadow-track-output-dirPathname of an existing directory where the application stores shadow track state output in a modified KITTI metadata format.Stringshadow-track-output-dir=­/home/­ubuntu/­shadow_data_tracker/dGPU, Jetsonglobal-gpu-idSet Global GPU ID for all the componenents at once if neededIntegerglobal-gpu-id=1dGPU, JetsonTiled-display Group#The tiled-display group properties are:Tiled display group#KeyMeaningType and ValueExamplePlatformsenableIndicates whether tiled display is enabled.
When user sets enable=2, first [sink] group with the key: link-to-demux=1 shall be linked to demuxer’s src_[source_id] pad where source_id is the key set in the corresponding [sink] group.Integer,
0 = disabled,
1 = tiler-enabled
2 = tiler-and-parallel-demux-to-sink-enabledenable=1dGPU, JetsonrowsNumber of rows in the tiled 2D array.Integer, >0rows=5dGPU, JetsoncolumnsNumber of columns in the tiled 2D array.Integer, >0columns=6dGPU, JetsonwidthWidth of the tiled 2D array, in pixels.Integer, >0width=1280dGPU, JetsonheightHeight of the tiled 2D array, in pixels.Integer, >0height=720dGPU, Jetsongpu-idGPU to be used by the element in case of multiple GPUs.Integer, ≥0gpu-id=0dGPUnvbuf-memory-typeType of memory the element is to allocate for output buffers.0 (nvbuf-mem-default): a platform-specific default type1 (nvbuf-mem-cuda-pinned): pinned/host CUDA memory2 (nvbuf-mem-cuda-device): device CUDA memory3 (nvbuf-mem-cuda-unified): unified CUDA memoryFor dGPU: All values are valid.For Jetson: Only 0 (zero) is valid.Integer, 0, 1, 2, or 3nvbuf-memory-type=3dGPU, Jetsoncompute-hwCompute Scaling HW to use. Applicable only for Jetson. dGPU systems uses GPU by default.0 (Default): Default, GPU for Tesla, VIC for Jetson1 (GPU): GPU2 (VIC): VICInteger: 0-2compute-hw=1Jetsonsquare-seq-gridEnable automatic square tiling according to number of sources. The tiles are placed sequentially on the grid with empty tiles at the endBooleansquare-seq-grid=1dGPU, JetsonSource Group#The source group specifies the source properties. The DeepStream application supports multiple simultaneous sources. For each source, a separate group with the group names such assource%dmust be added to the configuration file. For example:[source0]key1=value1key2=value2...[source1]key1=value1key2=value2...The source group properties are:Source group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the source.Booleanenable=1dGPU, JetsontypeType of source; other properties of the source depend on this type.1: Camera (V4L2)2: URI3: MultiURI4: RTSP5: Camera (CSI) (Jetson only)Integer,
1, 2, 3, 4, or 5type=1dGPU, JetsonuriURI to the encoded stream. The URI can be a file, an HTTP URI, or an RTSP live source. Valid when type=2 or 3. With MultiURI, the %d format specifier can also be used to specify multiple sources. The application iterates from 0 to num-sources−1 to generate the actual URIs.Stringuri=file:///home/ubuntu/source.mp4
uri=http://127.0.0.1/source.mp4
uri=rtsp://127.0.0.1/source1
uri=file:///home/ubuntu/source_%d.mp4dGPU, Jetsonnum-sourcesNumber of sources. Valid only when type=3.Integer, ≥0num-sources=2dGPU, Jetsonintra-decode-enableEnables or disables intra-only decode.Booleanintra-decode-enable=1dGPU, Jetsonnum-extra-surfacesNumber of surfaces in addition to minimum decode surfaces given by the decoder. Can be used to manage the number of decoder output buffers in the pipeline.Integer,
≥0 and ≤24num-extra-surfaces=5dGPU, Jetsongpu-idGPU to be used by the element in case of multiple GPUs.Integer, ≥0gpu-id=1dGPUcamera-idUnique ID for the input source to be added to metadata. (Optional)Integer, ≥0camera-id=2dGPU, Jetsoncamera-widthWidth of frames to be requested from the camera, in pixels. Valid when type=1 or 5.Integer, >0camera-width=1920dGPU, Jetsoncamera-heightHeight of frames to be requested from the camera, in pixels. Valid when type=1 or 5.Integer, >0camera-height=1080dGPU, Jetsoncamera-fps-nNumerator part of a fraction specifying the frame rate requested by the camera, in frames/sec. Valid when type=1 or 5.Integer, >0camera-fps-n=30dGPU, Jetsoncamera-fps-dDenominator part of a fraction specifying the frame rate requested from the camera, in frames/sec. Valid when type=1 or 5.Integer, >0camera-fps-d=1dGPU, Jetsoncamera-v4l2-dev-nodeNumber of the V4L2 device node. For example, /dev/video<num> for the open source V4L2 camera capture path. Valid when the type setting (type of source) is 1.Integer, >0camera-v4l2-dev-node=1dGPU, JetsonlatencyJitterbuffer size in milliseconds; applicable only for RTSP streams.Integer, ≥0latency=200dGPU, Jetsoncamera-csi-sensor-idSensor ID of the camera module. Valid when the type (type of source) is 5.Integer, ≥0camera-csi-sensor-id=1Jetsondrop-frame-intervalInterval to drop frames. For example, 5 means decoder outputs every fifth frame; 0 means no frames are dropped.Integer,drop-frame-interval=5dGPU, Jetsoncudadec-memtypeType of CUDA memory element used to allocate for output buffers for source of type 2,3 or 4. Not applicable for CSI or USB camera source0 (memtype_device): Device memory allocated with cudaMalloc().1 (memtype_pinned): host/pinned memory allocated with cudaMallocHost().2 (memtype_unified): Unified memory allocated with cudaMallocManaged().Integer,
0, 1, or 2cudadec-memtype=1dGPUnvbuf-memory-typeType of CUDA memory the element is to allocate for output buffers of nvvideoconvert, useful for source of type 1.0 (nvbuf-mem-default, a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned/host CUDA memory.2 (nvbuf-mem-cuda-device): Device CUDA memory.3 (nvbuf-mem-cuda-unified): Unified CUDA memory.For dGPU: All values are valid.For Jetson: Only 0 (zero) is valid.Integer,
0, 1, 2, or 3nvbuf-memory-type=3dGPU,Jetsonselect-rtp-protocolTransport Protocol to use for RTP. Valid when type (type of source) is 4.0: UDP + UDP Multicast + TCP4: TCP onlyInteger,
0 or 4select-rtp-protocol=4dGPU, Jetsonrtsp-reconnect-interval-secTimeout in seconds to wait since last data was received from an RTSP source before forcing a reconnection. Setting it to 0 will disable the reconnection. Valid when type (type of source) is 4.Integer, ≥0rtsp-reconnect-interval-sec=60dGPU, Jetsonrtsp-reconnect-attemptsMaximum number of times a reconnection is attempted. Setting it to -1 means reconnection will be attempted infinitely. Valid when type of source is 4 and rtsp-reconnect-interval-sec is a non-zero positive value.Integer, ≥-1rtsp-reconnect-attempts=2smart-recordWays to trigger the smart record.0: Disable1: Only through cloud messages2: Cloud message + Local eventsInteger,
0, 1 or 2smart-record=1dGPU, Jetsonsmart-rec-dir-pathPath of directory to save the recorded file. By default, the current directory is used.Stringsmart-rec-dir-path=/home/nvidia/dGPU, Jetsonsmart-rec-file-prefixPrefix of file name for recorded video. By default, Smart_Record is the prefix. For unique file names every source must be provided with a unique prefix.Stringsmart-rec-file-prefix=Cam1dGPU, Jetsonsmart-rec-cacheSize of smart record cache in seconds.Integer, ≥0smart-rec-cache=20dGPU, Jetsonsmart-rec-containerContainer format of recorded video. MP4 and MKV containers are supported.Integer,
0 or 1smart-rec-container=0dGPU, Jetsonsmart-rec-start-timeNumber of seconds earlier from now to start the recording.
E.g. if t0 is the current time and N is the start time in seconds that means recording will start from t0 – N. Obviously for it to work the video cache size must be greater than the N.Integer, ≥0smart-rec-start-time=5dGPU, Jetsonsmart-rec-default-durationIn case a Stop event is not generated. This parameter will ensure the recording is stopped after a predefined default duration.Integer, ≥0smart-rec-default-duration=20dGPU, Jetsonsmart-rec-durationDuration of recording in seconds.Integer, ≥0smart-rec-duration=15dGPU, Jetsonsmart-rec-intervalThis is the time interval in seconds for SR start / stop events generation.Integer, ≥0smart-rec-interval=10dGPU, Jetsonudp-buffer-sizeUDP buffer size in bytes for RTSP sources.Integer, ≥0udp-buffer-size=2000000dGPU, Jetsonvideo-formatOutput video format for the source. This value is set as the output format of the nvvideoconvert element for the source.String: NV12, I420, P010_10LE, BGRx, RGBAvideo-format=RGBAdGPU, JetsonSource-list and source-attr-all Groups#The source-list group allows users to provide an initial list of source URI to start streaming with.
This group along with [source-attr-all] can replace the need for separate [source] groups for each stream.Also, DeepStream support (Alpha feature) dynamic sensor provisioning via REST API.
For more details on this feature, please refer to the sample configuration file and deepstream reference application run commandhere.For example:[source-list]num-source-bins=2list=file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4;file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h265.mp4sgie-batch-size=8...[source-attr-all]enable=1type=3num-sources=1gpu-id=0cudadec-memtype=0latency=100rtsp-reconnect-interval-sec=0...Note: [source-list] now support REST Server with use-nvmultiurisrcbin=1For example:[source-list]num-source-bins=2list=file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4;file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h265.mp4use-nvmultiurisrcbin=1#sensor-id-list vector is one to one mapped with the uri-list#identifies each sensor by a unique IDsensor-id-list=UniqueSensorId1;UniqueSensorId2#Optional sensor-name-list vector is one to one mapped with the uri-listsensor-name-list=UniqueSensorName1;UniqueSensorName2max-batch-size=10http-ip=localhosthttp-port=9000#sgie batch size is number of sources * fair fraction of number of objects detected per frame per source#the fair fraction of number of object detected is assumed to be 4sgie-batch-size=40[source-attr-all]enable=1type=3num-sources=1gpu-id=0cudadec-memtype=0latency=100rtsp-reconnect-interval-sec=0The [source-list] group properties are:Source List group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the source.Booleanenable=1dGPU, Jetsonnum-source-binsThe total number of source URI’s provided with the key listIntegernum-source-bins=2dGPU, Jetsonsgie-batch-sizesgie batch size is number of sources * fair fraction of number of objects detected per frame per source
the fair fraction of number of object detected is assumed to be 4Integersgie-batch-size=8dGPU, JetsonlistThe list of URI’s separated by semi-colon ‘;’Stringlist=rtsp://ip-address:port/stream1;rtsp://ip-address:port/stream2dGPU, Jetsonsensor-id-list(Alpha Feature) Applicable only when use-nvmultiurisrcbin=1. The list of unique Identifiers identifying each stream separated by semi-colon ‘;’Stringsensor-id-list=UniqueSensorId1;UniqueSensorId2dGPUsensor-name-list(Alpha Feature) Applicable only when use-nvmultiurisrcbin=1. The Optional list of sensor names identifying each stream separated by semi-colon ‘;’Stringsensor-name-list=SensorName1;SensorName2dGPUuse-nvmultiurisrcbin(Alpha Feature) Boolean if set enable the use of nvmultiurisrcbin with REST API support for dynamic sensor provisioningBooleanuse-nvmultiurisrcbin=0(default)dGPUmax-batch-size(Alpha Feature) Applicable only when use-nvmultiurisrcbin=1. Sets the maximum number of sensors that can be streamed using this instance of DeepStreamIntegermax-batch-size=10dGPUhttp-ip(Alpha Feature) Applicable only when use-nvmultiurisrcbin=1. The HTTP Endpoint IP address to useStringhttp-ip=localhost (default)dGPUhttp-port(Alpha Feature) Applicable only when use-nvmultiurisrcbin=1. The HTTP Endpoint port number to use. Note: User may pass empty string to disable REST API serverStringhttp-ip=9001 (default)dGPUThe [source-attr-all] group support all properties except uri from theSource Group.
A sample config file can be found at/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-test5/configs/test5_config_file_nvmultiurisrcbin_src_list_attr_all.txt.Streammux Group#The [streammux] group specifies and modifies properties of theGst-nvstreammuxplugin.Streammux group#KeyMeaningType and ValueExamplePlatformsgpu-idGPU element is to use in case of multiple GPUs.Integer, ≥0gpu-id=1dGPUlive-sourceInforms the muxer that sources are live.Booleanlive-source=0dGPU, Jetsonbuffer-pool-sizeNumber of buffers in Muxer output buffer pool.Integer, >0buffer-pool-size=4dGPU, Jetsonbatch-sizeMuxer batch size.Integer, >0batch-size=4dGPU, Jetsonbatched-push-timeoutTimeout in microseconds after to push the batch after the first buffer is available, even if the complete batch is not formed.Integer, ≥−1batched-push-timeout=40000dGPU, JetsonwidthMuxer output width in pixels.Integer, >0width=1280dGPU, JetsonheightMuxer output height in pixels.Integer, >0height=720dGPU, Jetsonenable-paddingIndicates whether to maintain source aspect ratio when scaling by adding black bands.Booleanenable-padding=0dGPU, Jetsonnvbuf-memory-typeType of CUDA memory the element is to allocate for output buffers.0 (nvbuf-mem-default, a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned/host CUDA memory.2 (nvbuf-mem-cuda-device): Device CUDA memory.3 (nvbuf-mem-cuda-unified): Unified CUDA memory.For dGPU: All values are valid.For Jetson: Only 0 (zero) is valid.Integer,
0, 1, 2, or 3nvbuf-memory-type=3dGPUattach-sys-ts-as-ntpFor live sources, the muxed buffer shall have associated NvDsFrameMeta->ntp_timestamp set to system time or the server’s NTP time when streaming RTSP.If set to 1, system timestamp will be attached as ntp timestamp.If set to 0, ntp timestamp from rtspsrc, if available, will be attached.Booleanattach-sys-ts-as-ntp=0dGPU, Jetsonconfig-file-pathThis key is valid only for the new streammux. Please refer the plugin manual section “New Gst-nvstreammux” for more information.
Absolute or relative (to DS config-file location) path of mux configuration file.Stringconfig-file-path=config_mux_source30.txtdGPU, Jetsonsync-inputsTime synchronize input frames before batching them.Booleansync-inputs=0 (default)dGPU, Jetsonmax-latencyAdditional latency in live mode to allow upstream to take longer to produce buffers for the current position (in nanoseconds).Integer, ≥0max-latency=0 (default)dGPU, Jetsondrop-pipeline-eosBoolean property to control EOS propagation downstream from nvstreammux when all the sink pads are at EOS. (Experimental)Booleandrop-pipeline-eos=0(default)dGPU/JetsonPreprocess Group#The[pre-process]group is for addingnvdspreprocessplugin in the pipeline. Supports preprocessing for only Primary GIE.Preprocess group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the plugin.Booleanenable=1dGPU, Jetsonconfig-fileConfiguration file path for nvdspreprocess pluginStringconfig-file=config_preprocess.txtdGPU, JetsonPrimary GIE and Secondary GIE Group#The DeepStream application supports multiple secondary GIEs. For each secondary GIE, a separate group with the namesecondary-gie%dmust be added to the configuration file. For example:[primary-gie]key1=value1key2=value2...[secondary-gie1]key1=value1key2=value2...The primary and secondary GIE configurations are as follows. For each configuration, the Valid for column indicates whether the configuration property is valid for the primary or secondary TensorRT model, or for both models.Primary and Secondary GIE* group#KeyMeaningType and ValueExamplePlatforms/ GIEs*enableIndicates whether the primary GIE must be enabled.Booleanenable=1dGPU, Jetson
Both GIEsgie-unique-idUnique component ID to be assigned to the nvinfer instance. Used to identify metadata generated by the instance.Integer, >0gie-unique-id=2Bothgpu-idGPU to be used by the element in case of multiple GPUs.Integer, ≥0gpu-id=1dGPU, Both GIEsmodel-engine-fileAbsolute pathname of the pre-generated serialized engine file for the mode.Stringmodel-engine-file=­../../models/­Primary_Detector/­resnet18_trafficcamnet_pruned.onnx_b4_gpu0_int8.engineBoth GIEsnvbuf-memory-typeType of CUDA memory element is to allocate for output buffers.0 (nvbuf-mem-default): a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned/host CUDA memory2 (nvbuf-mem-cuda-device): Device CUDA memory3 (nvbuf-mem-cuda-unified): Unified CUDA memoryFor dGPU: All values are valid.For Jetson: Only 0 (zero) is valid.Integer,
0, 1, 2, or 3nvbuf-memory-type=3dGPU, Jetson
Primary GIEconfig-filePathname of a configuration file which specifies properties for the Gst-nvinfer plugin. It may contain any of the properties described in this table except config-file itself. Properties must be defined in a group named [property].
For more details about parameters see “Gst-nvinfer File Configuration Specifications” in the DeepStream 4.0 Plugin Manual.Stringconfig-file=¬/home/-ubuntu/-config_infer_resnet.txt
For complete examples, see the sample file samples/¬configs/-deepstream-app/-config_infer_resnet.txt or the deepstream-test2 sample application.dGPU, Jetson
Both GIEsbatch-sizeThe number of frames(P.GIE)/objects(S.GIE) to be inferred together in a batch.Integer, >0 Integer, >0batch-size=2dGPU, Jetson
Both GIEsintervalNumber of consecutive batches to skip for inference.Integer, >0 Integer, >0interval=2dGPU, Jetson
Primary GIEbbox-border-colorThe color of the borders for the objects of a specific class ID, specified in RGBA format. The key must be of format bbox-border-color<class-id>. This property can be identified multiple times for multiple class IDs. If this property is not identified for the class ID, the borders are not drawn for objects of that class-id.R:G:B:A Float,
0≤R,G,B,A≤1bbox-border-color2=
1;0;0;1
(Red for class-id 2)dGPU, Jetson
Both GIEsbbox-bg-colorThe color of the boxes drawn over objects of a specific class ID, in RGBA format. The key must be of format bbox-bg-color<class-id>. This property can be used multiple times for multiple class IDs. If it is not used for a class ID, the boxes are not drawn for objects of that class ID.R:G:B:A Float,
0≤R,G,B,A≤1bbox-bg-color3=-0;1;0;0.3
(Semi-transparent green for class-id 3)dGPU, Jetson
Both GIEsoperate-on-gie-idA unique ID of the GIE, on whose metadata (NvDsFrameMeta) this GIE is to operate.Integer, >0operate-on-gie-id=1dGPU, Jetson Secondary GIEoperate-on-class-idsClass IDs of the parent GIE on which this GIE must operate. The parent GIE is specified using operate-on-gie-id.Semicolon separated integer arrayoperate-on-class-ids=1;2
(operate on objects with class IDs 1, 2 generated by parent GIE)dGPU, Jetson
Secondary GIEinfer-raw-output-dirPathname of an existing directory in which to dump the raw inference buffer contents in a file.Stringinfer-raw-output-dir=­/home/­ubuntu/­infer_raw_outdGPU, Jetson
Both GIEslabelfile-pathPathname of the labelfile.Stringlabelfile-path=../../models/Primary_Detector/labels.txtdGPU, Jetson
Both GIEsplugin-typePlugin to use for inference.
0: nvinfer (TensorRT)
1: nvinferserver (Triton inference server)Integer,
0 or 1plugin-type=1dGPU, Jetson
Both GIEsinput-tensor-metaUse preprocessed input tensors attached as metadata by nvdspreprocess plugin instead of preprocessing inside the nvinfer.Integer, 0 or 1input-tensor-meta=1dGPU, Jetson, Primary GIENote* The GIEs are the GPU Inference Engines.Tracker Group#The tracker group properties include the following, and more details can be found inGst Properties:Tracker group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the tracker.Booleanenable=1dGPU, Jetsontracker-widthFrame width at which the tracker will operate, in pixels. (To be a multiple of 32 when tracker config visualTrackerType: 1 or reidType is non-zero with useVPICropScaler: 0)Integer, ≥0tracker-width=960dGPU, Jetsontracker-heightFrame height at which the tracker will operate, in pixels. (To be a multiple of 32 when tracker config visualTrackerType: 1 or reidType is non-zero with useVPICropScaler: 0)Integer, ≥0tracker-height=544dGPU, Jetsongpu-idGPU to be used by the element in case of multiple GPUs.Integer, ≥0gpu-id=1dGPUll-config-fileConfiguration file for the low-level library if needed.(Alpha feature) A list of configuration files can be specified when the propertysub-batchesis configured.Stringll-config-file=iou_config.txtdGPU, Jetsonll-lib-filePathname for the low-level tracker implementation library.Stringll-lib-file=/usr/-local/deepstream/libnvds_mot_iou.sodGPU, Jetsontracking-surface-typeSet surface stream type for tracking. (default value is 0)Integer, ≥0tracking-surface-type=0dGPU, Jetsondisplay-tracking-idEnables tracking id display.Booleandisplay-tracking-id=1dGPU, Jetsontracking-id-reset-modeAllow force-reset of tracking ID based on pipeline event. Once tracking ID reset is enabled and such event happens, the lower 32-bit of the tracking ID will be reset to 00: Not reset tracking ID when stream reset or EOS event happens1: Terminate all existing trackers and assign new IDs for a stream when the stream reset happens (i.e., GST_NVEVENT_STREAM_RESET)2: Let tracking ID start from 0 after receiving EOS event  (i.e., GST_NVEVENT_STREAM_EOS) (Note: Only the lower 32-bit of tracking ID to start from 0)3: Enable both option 1 and 2Integer, 0 to 3tracking-id-reset-mode=0dGPU, Jetsoninput-tensor-metaUse the tensor-meta from Gst-nvdspreprocess if available for tensor-meta-gie-idBooleaninput-tensor-meta=1dGPU, Jetsontensor-meta-gie-idTensor Meta GIE ID to be used, property valid only if input-tensor-meta is TRUEUnsigned Integer, ≥0tensor-meta-gie-id=5dGPU, Jetsonsub-batches (Alpha feature)Configures splitting of a batch of frames in sub-batchesSemicolon delimited integer array.Must include all values from 0 to (batch-size -1) where batch-size is configured in[streammux].sub-batches=0,1;2,3In this example, a batch size of 4 is split into two sub-batches where the first sub-batch consists of source ids 0 & 1 and second sub-batch consists of source ids 2 & 3dGPU, Jetsonsub-batch-err-recovery-trial-cnt (Alpha feature)Configure the number of times the plugin can try to recover when the low level tracker in a sub-batch returns with a fatal error.To recover from the error, the plugin reinitializes the low level tracker library.Integer,≥-1  where,-1 corresponds to infinite trialssub-batch-err-recovery-trial-cnt=3dGPU, Jetsonuser-meta-pool-sizeThe size of tracker miscellaneous data buffer poolUnsigned Integer, >0user-meta-pool-size=32dGPU, JetsonMessage Converter Group#Message converter group properties are:Message converter group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the message converter.Booleanenable=1dGPU, Jetsonmsg-conv-configPathname of the configuration file for the Gst-nvmsgconv element.Stringmsg-conv-config=dstest5_msgconv_sample_config.txtdGPU, Jetsonmsg-conv-payload-typeType of payload.0, PAYLOAD_DEEPSTREAM: Deepstream schema payload.1, PAYLOAD_DEEPSTREAM_MINIMAL: Deepstream schema payload minimal.256, PAYLOAD_RESERVED: Reserved type.257, PAYLOAD_CUSTOM: Custom schema payload.Integer
0, 1, 256, or 257msg-conv-payload-type=0dGPU, Jetsonmsg-conv-msg2p-libAbsolute pathname of an optional custom payload generation library. This library implements the API defined by sources/libs/nvmsgconv/nvmsgconv.h.Stringmsg-conv-msg2p-lib=/opt/nvidia/deepstream/deepstream-4.0/lib/libnvds_msgconv.sodGPU, Jetsonmsg-conv-comp-idcomp-id Gst property of the gst-nvmsgconv element.
This is the Id of the component that attaches the NvDsEventMsgMeta which must be processed by gst-nvmsgconv element.Integer, >=0msg-conv-comp-id=1dGPU, Jetsondebug-payload-dirDirectory to dump payloadStringdebug-payload-dir=<absolute path> Default is NULLdGPU Jetsonmultiple-payloadsGenerate multiple message payloadsBooleanmultiple-payloads=1 Default is 0dGPU Jetsonmsg-conv-msg2p-new-apiGenerate payloads using Gst buffer frame/object metadataBooleanmsg-conv-msg2p-new-api=1 Default is 0dGPU Jetsonmsg-conv-frame-intervalFrame interval at which payload is generatedInteger, 1 to  4,294,967,295msg-conv-frame-interval=25 Default is 30dGPU Jetsonmsg-conv-dummy-payloadBy default payload is generated if NVDS_EVENT_MSG_META is attached to buffer. With this dummy payload can be generated if there is no  NVDS_EVENT_MSG_META attached to bufferbooleanmsg-conv-dummy-payload=true Default is falsedGPU JetsonMessage Consumer Group#Message consumer group properties are:Message consumer group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the message consumer.Booleanenable=1dGPU, Jetsonproto-libPath to the library having protocol adapter implementation.Stringproto-lib=/opt/nvidia/deepstream/deepstream-4.0/lib/libnvds_kafka_proto.sodGPU, Jetsonconn-strConnection string of the server.Stringconn-str=foo.bar.com;80dGPU, Jetsonconfig-filePath to the file having additional configurations for protocol adapter,Stringconfig-file=../cfg_kafka.txtdGPU, Jetsonsubscribe-topic-listList of topics to subscribe.Stringsubscribe-topic-list=toipc1;topic2;topic3dGPU, Jetsonsensor-list-fileFile having mappings from sensor index to sensor name.Stringsensor-list-file=dstest5_msgconv_sample_config.txtdGPU, JetsonOSD Group#The OSD group specifies the properties and modifies the behavior of the OSD component, which overlays text and rectangles on the video frame.OSD group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the On-Screen Display (OSD).Booleanenable=1dGPU, Jetsongpu-idGPU to be used by the element in case of multiple GPUs.Integer, ≥0gpu-id=1dGPUborder-widthBorder width of the bounding boxes drawn for objects, in pixels.Integer, ≥0border-width=10dGPU, Jetsonborder-colorBorder color of the bounding boxes drawn for objects.R;G;B;A Float,
0≤R,G,B,A≤1border-color=0;0;0.7;1 #Dark BluedGPU, Jetsontext-sizeSize of the text that describes the objects, in points.Integer, ≥0text-size=16dGPU, Jetsontext-colorThe color of the text that describes the objects, in RGBA format.R;G;B;A Float,
0≤R,G,B,A≤1text-color=0;0;0.7;1 #Dark BluedGPU, Jetsontext-bg-colorThe background color of the text that describes the objects, in RGBA format.R;G;B;A Float,
0≤R,G,B,A≤1text-bg-color=0;0;0;0.5 #Semi-transparent blackdGPU, Jetsonclock-text-sizeThe size of the clock time text, in points.Integer, >0clock-text-size=16dGPU, Jetsonclock-x-offsetThe horizontal offset of the clock time text, in pixels.Integer, >0clock-x-offset=100dGPU, Jetsonclock-y-offsetThe vertical offset of the clock time text, in pixels.Integer, >0clock-y-offset=100dGPU, JetsonfontName of the font for text that describes the objects.Stringfont=PurisadGPU, JetsonEnter the shell command fc-list to display the names of available fonts.clock-colorColor of the clock time text, in RGBA format.R;G;B;A Float,
0≤R,G,B,A≤1clock-color=1;0;0;1 #ReddGPU, Jetsonnvbuf-memory-typeType of CUDA memory the element is to allocate for output buffers.0 (nvbuf-mem-default): a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned/host CUDA memory2 (nvbuf-mem-cuda-device): Device CUDA memory3 (nvbuf-mem-cuda-unified): Unified CUDA memoryFor dGPU: All values are valid.For Jetson: Only 0 (zero) is valid.Integer,
0, 1, 2, or 3nvbuf-memory-type=3dGPUprocess-modeNvOSD processing mode.0: CPU1: GPUInteger,
0, 1, or 2process-mode=1dGPU, Jetsondisplay-textIndicate whether to display textBooleandisplay-text=1dGPU, Jetsondisplay-bboxIndicate whether to bounding boxBooleandisplay-bbox=1dGPU, Jetsondisplay-maskIndicate whether to display instance maskBooleandisplay-mask=1dGPU, JetsonSink Group#The sink group specifies the properties and modifies the behavior of the sink components for rendering, encoding, and file saving.Sink group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the sink.Booleanenable=1dGPU, JetsontypeType of sink, to use.1: Fakesink2: EGL based windowed nveglglessink for dGPU and nv3dsink for Jetson3: Encode + File Save (encoder + muxer + filesink)4: Encode + RTSP streaming; Note: sync=1 for this type is not applicable;5: nvdrmvideosink (Jetson only)6: Message converter + Message brokerInteger, 1, 2, 3, 4, 5 or 6type=2dGPU, JetsonsyncIndicates how fast the stream is to be rendered.0: As fast as possible1: SynchronouslyInteger,
0 or 1sync=1dGPU, JetsonqosIndicates whether the sink is to generate Quality-of-Service events, which can lead to the pipeline dropping frames when pipeline FPS cannot keep up with the stream frame rate.Booleanqos=0dGPU, Jetsonsource-idThe ID of the source whose buffers this sink must use. The source ID is contained in the source group name. For example, for group [source1] source-id=1.Integer, ≥0source-id=1dGPU, Jetsongpu-idGPU to be used by the element in case of multiple GPUs.Integer, ≥0gpu-id=1dGPUcontainerContainer to use for the file save. Only valid for type=3.1: MP42: MKVInteger,
1 or 2container=1dGPU, JetsoncodecThe encoder to be used to save the file.1: H.264 (hardware)2: H.265 (hardware)Integer,
1 or 2codec=1dGPU, JetsonbitrateBitrate to use for encoding, in bits per second. Valid for type=3 and 4.Integer, >0bitrate=4000000dGPU, JetsoniframeintervalEncoding intra-frame occurrence frequency.Integer,
0≤iv≤MAX_INTiframeinterval=30dGPU, Jetsonoutput-filePathname of the output encoded file. Only valid for type=3.Stringoutput-file=­/home/­ubuntu/­output.mp4dGPU, Jetsonnvbuf-memory-typeType of CUDA memory the plugin is to allocate for output buffers.0 (nvbuf-mem-default): a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned/host CUDA memory2 (nvbuf-mem-cuda-device): Device CUDA memory3 (nvbuf-mem-cuda-unified): Unified CUDA memoryFor dGPU: All values are valid.For Jetson: Only 0 (zero) Is valid.Integer,
0, 1, 2, or 3nvbuf-memory-type=3dGPU, Jetsonrtsp-portPort for the RTSP streaming server; a valid unused port number. Valid for type=4.Integerrtsp-port=8554dGPU, Jetsonudp-portPort used internally by the streaming implementation - a valid unused port number. Valid for type=4.Integerudp-port=5400dGPU, Jetsonconn-idConnection index. Valid for nvdrmvideosink(type=5).Integer, >=1conn-id=0JetsonwidthWidth of the renderer in pixels.Integer, >=1width=1920dGPU, JetsonheightHeight of the renderer in pixels.Integer, >=1height=1920dGPU, Jetsonoffset-xHorizontal offset of the renderer window, in pixels.Integer, >=1offset-x=100dGPU, Jetsonoffset-yVertical offset of the renderer window, in pixels.Integer, >=1offset-y=100dGPU, Jetsonplane-idPlane on which video should be rendered. Valid for nvdrmvideosink(type=5).Integer, ≥0plane-id=0Jetsonmsg-conv-configPathname of the configuration file for the Gst-nvmsgconv element (type=6).Stringmsg-conv-config=dstest5_msgconv_sample_config.txtdGPU, Jetsonmsg-broker-proto-libPath to the protocol adapter implementation used Gst-nvmsgbroker (type=6).Stringmsg-broker-proto-lib= /opt/nvidia/deepstream/deepstream-5.0/lib/libnvds_amqp_proto.sodGPU, Jetsonmsg-broker-conn-strConnection string of the backend server (type=6).Stringmsg-broker-conn-str=foo.bar.com;80;dsappdGPU, JetsontopicName of the message topic (type=6).Stringtopic=test-ds4dGPU, Jetsonmsg-conv-payload-typeType of payload.0, PAYLOAD_DEEPSTREAM: DeepStream schema payload.1, PAYLOAD_DEEPSTREAM_-MINIMAL: DeepStream schema payload minimal.256, PAYLOAD_RESERVED: Reserved type.257, PAYLOAD_CUSTOM: Custom schema payload (type=6).Integer 0, 1, 256, or 257msg-conv-payload-type=0dGPU, Jetsonmsg-broker-configPathname of an optional configuration file for the Gst-nvmsgbroker element (type=6).Stringmsg-broker-config=/home/ubuntu/cfg_amqp.txtdGPU, Jetsonsleep-timeSleep time between consecutive do_work calls in millisecondsInteger >= 0. 
For Azure, use value >= 10 depending on IoT Hub service tier message rate limit.
Warning: failure is likely with unreasonably high sleep times, e.g. 10000000 mssleep-time=10dGPU
Jetsonnew-apiuse protocol adapter library api’s directly or use new msgbroker library wrapper api’s (type=6)Integer0 : Use adapter api’s directly1 : msgbroker lib wrapper api’snew-api = 0dGPU, Jetsonmsg-conv-msg2p-libAbsolute pathname of an optional custom payload generation library. This library implements the API defined by sources/libs/nvmsgconv/­nvmsgconv.h.
Applicable only when msg-conv-payload-type=257, PAYLOAD_CUSTOM. (type=6)Stringmsg-conv-msg2p-lib= /opt/nvidia/deepstream/deepstream-4.0/lib/libnvds_msgconv.sodGPU, Jetsonmsg-conv-comp-idcomp-id Gst property of the nvmsgconv element; ID (gie-unique-id) of the primary/secondary-gie component from which metadata is to be processed. (type=6)Integer, >=0msg-conv-comp-id=1dGPU, Jetsonmsg-broker-comp-idcomp-id Gst property of the nvmsgbroker element; ID (gie-unique-id) of the primary/secondary gie component from which metadata is to be processed. (type=6)Integer, >=0msg-broker-comp-id=1dGPU, Jetsondebug-payload-dirDirectory to dump payload (type=6)Stringdebug-payload-dir=<absolute path> Default is NULLdGPU Jetsonmultiple-payloadsGenerate multiple message payloads (type=6)Booleanmultiple-payloads=1 Default is 0“dGPU Jetson”msg-conv-msg2p-new-apiGenerate payloads using Gst buffer frame/object metadata (type=6)Booleanmsg-conv-msg2p-new-api=1 Default is 0“dGPU Jetson”msg-conv-frame-intervalFrame interval at which payload is generated (type=6)Integer, 1 to  4,294,967,295msg-conv-frame-interval=25 Default is 30dGPU Jetsondisable-msgconvOnly add a message broker component instead of a message converter + message broker. (type=6)Integer,disable-msgconv = 1dGPU, Jetsonenc-typeEngine to use for encoder0: NVENC hardware engine1: CPU software encoderInteger,
0 or 1enc-type=0dGPU, Jetsonprofile (HW)Encoder profile for the codec
V4L2 H264 encoder(HW):0: Baseline2: Main4: HighV4L2 H265 encoder(HW):0: Main1: Main10Integer,
valid values from the column besideprofile=2dGPU, Jetsonudp-buffer-sizeUDP kernel buffer size (in bytes) for internal RTSP output pipeline.Integer, >=0udp-buffer-size=100000dGPU, Jetsonlink-to-demuxA boolean which enables or disables streaming a particular “source-id” alone to this sink. Please check the tiled-display group enable key for more information.Booleanlink-to-demux=0dGPU, JetsonTests Group#The tests group is for diagnostics and debugging.Tests group#KeyMeaningType and ValueExamplePlatformsfile-loopIndicates whether input files should be looped infinitely.Booleanfile-loop=1dGPU, JetsonNvDs-analytics Group#The[nvds-analytics]group is for addingnvds-analyticsplugin in the pipeline.NvDs-analytics group#KeyMeaningType and ValueExamplePlatformsenableEnables or disables the plugin.Booleanenable=1dGPU, Jetsonconfig-fileConfiguration file path for nvdsanalytics pluginStringconfig-file=config_nvdsanalytics.txtdGPU, JetsonNoteSee the DeepStream Plugin Guide for plugin-specific configuration file specifications (for theGst-nvdspreprocess,Gst-nvinfer,Gst-nvtracker,Gst-nvdewarper,Gst-nvmsgconv,Gst-nvmsgbrokerandGst-nvdsanalyticsplugins).Application Tuning for DeepStream SDK#This section provides application tuning tips for the DeepStream SDK using the following parameters in the configuration file.Performance Optimization#This section covers various performance optimization steps that you can try for maximum performance.DeepStream best practices#Here are few best practices to optimize DeepStream application to remove bottlenecks in your application:Set the batch size of streammux and primary detector to equal the number of input sources. These settings are under[streammux]and[primary-gie]group of the config file. This keeps the pipeline running at full capacity. Higher or lower batch size than number of input sources can sometimes add latency in the pipeline.Set the height and width of streammux to the input resolution. This is set under[streammux]group of the config file. This ensures that stream doesn’t go through any unwanted image scaling.If you are streaming from live sources such as RTSP or from USB camera, setlive-source=1in[streammux]group of config file. This enables proper timestamping for live sources creating smoother playbackTiling and visual output can take up GPU resource. There are 3 things that you can disable to maximize throughput when you do not need to render the output on your screen. As an example, rendering is not required when you want to run inference on the edge and transmit just the metadata to the cloud for further processing.Disable OSD or on-screen display. OSD plugin is used for drawing bounding boxes and other artifacts and adding labels in the output frame. To disable OSD set enable=0 in the[osd]group of the config file.The tiler creates anNxMgrid for displaying the output streams. To disable the tiled output, set enable=0 in the[tiled-display]group of the config file.Disable the output sink for rendering: choosefakesink, that is,type=1in the[sink]group of the config file. All the performance benchmark in Performance section are ran with tiling, OSD and output sink disabled.If CPU/GPU utilization is low, then one of the possibilities is that the elements in the pipeline are getting starved for buffers. Then try increasing the number of buffers allocated by the decoder by setting thenum-extra-surfacesproperty of the[source#]group in the application or thenum-extra-surfacesproperty ofGst-nvv4l2decoderelement.If you are running the application inside docker console and it delivers low FPS, setqos=0in the configuration file’s[sink0]group. The issue is caused by initial load. When qos set to 1, as the property’s default value in the[sink0]group,decodebinstarts dropping frames.If you want to optimize processing pipelines end to end latency you can use latency measurement method in DeepStream.To enable frame latency measurement, run this command on the console:$exportNVDS_ENABLE_LATENCY_MEASUREMENT=1To enable latency for all plugins, run this command on the console:$exportNVDS_ENABLE_COMPONENT_LATENCY_MEASUREMENT=1NoteWhen measuring frame latency using DeepStream latency APIs if large frame latency numbers in the order of10^12or1e12are observed, modify the latency measurement code (call tonvds_measure_buffer_latencyAPI) to...guintnum_sources_in_batch=nvds_measure_buffer_latency(buf,latency_info);if(num_sources_in_batch>0&&latency_info[0].latency>1e6){NvDsBatchMeta*batch_meta=gst_buffer_get_nvds_batch_meta(buf);batch_meta->batch_user_meta_list=g_list_reverse(batch_meta->batch_user_meta_list);num_sources_in_batch=nvds_measure_buffer_latency(buf,latency_info);}...Jetson optimization#Ensure that Jetson clocks are set high. Run these commands to set Jetson clocks high.$sudonvpmodel-m<mode>--forMAXperfandpowermodeis0$sudojetson_clocksNoteFor NX: use mode as 2.On Jetson, useGst-nvdrmvideosinkinstead ofGst-nv3dsinkasnv3dsinkrequires GPU utilization.Triton#If you are using Triton with DeepStream, tunetf_gpu_memory_fractionvalues for TensorFlow GPU memory usage per process - suggested range [0.2, 0.6]. Too large value  can cause Out-of-memory and too small may cause low perf.Enable TensorRT optimization when using TensorFlow or ONNX with Triton. Update Triton config file to enable TensorFlow/ONNX TensorRT online optimization. This will take several minutes during initialization each time. Alternatively, you can generate TF-TRTgraphdef/savedmodelmodels offline.Inference Throughput#Here are a few steps to help you increase channel density for your application:If you are using Jetson AGX Orin or Jetson Orin NX, you can use the DLA (Deep learning accelerator) for inferencing. This frees GPU for other models or more streams.With DeepStream, users can infer every other frame or every third frame and use a tracker to predict the location in the object. This can be done with a simple config file change. Users can use one of the 3 available trackers to track the object in the frame. In the inference config file, change the interval parameter under[property]. This is a skip interval, number of frames to skip between inference. Interval of 0 means infer every frames and interval of 1 means skip 1 frame and infer every other frame. This can effectively double your overall channel throughput by going from interval of 0 to 1.Choose lower precision such as FP16 or INT8 for inference. If you want to use FP16, no new model is required. This is a simple change in the DS. To change, update the network-mode option in the inference config file. If you want to run INT8, an INT8 calibration cache is required which contains the FP32 to INT8 quantization table.DeepStream app can also be configured to have cascaded neural network. First network does the detection followed by second network with does some classification on the detection. To enable secondary inference, enable the secondary-gie from the config file. Set the appropriate batch sizes. Batch size will depend on number of objects that are typically sent to the secondary inference from primary inference. You’ll have to experiment to see what the appropriate batch size for their use case is. To reduce the number of inferences of the secondary classifier, the objects to infer on can be filtered by settinginput-object-min-width,input-object-min-height,input-object-max-width,input-object-max-height,operate-on-gie-id,operate-on-class-idsappropriately.Reducing Spurious Detections#Reducing spurious detections#Configuration ParameterDescriptionUse CasethresholdPer-class-threshold of primary detector.
Increasing the threshold restricts output to objects with higher detection confidence.—roi-top-offset
roi-bottom-offsetPer-class top/bottom region of interest (roi) offset.
Restricts output to objects in a specified region of the frame.To reduce spurious detections seen on the dashboard of dashcamsdetected-min-w
detected-min-h
detected-max-w
detected-max-hPer-class min/max object width/height for primary-detector
Restricts output to objects of specified size.To reduce false detections, for example, a tree being detected as a personpreviousPython Sample Apps and Bindings Source DetailsnextDeepStream Reference Application - deepstream-test5 appOn this pageApplication ArchitectureReference Application ConfigurationExpected Output for the DeepStream Reference Application (deepstream-app)Configuration GroupsApplication GroupTiled-display GroupSource GroupSource-list and source-attr-all GroupsStreammux GroupPreprocess GroupPrimary GIE and Secondary GIE GroupTracker GroupMessage Converter GroupMessage Consumer GroupOSD GroupSink GroupTests GroupNvDs-analytics GroupApplication Tuning for DeepStream SDKPerformance OptimizationDeepStream best practicesJetson optimizationTritonInference ThroughputReducing Spurious DetectionsPrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.