DeepStream 3D Lidar Inference App â€” DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formDeepStream...DeepStream 3D Lidar Inference App#Thedeepstream-lidar-inference-appsample application is provided atapp/sample_apps/deepstream-lidar-inference-app/for your reference. Thedeepstream_lidar_inference_appprovides an end-to-end inference sample for lidar pointcloud data.
The sample application reads the point cloud data from dataset files and send the data to Triton Inferencing filter withPointPillarNet model, the inferencing result is the group of 3D bounding boxes of the objects. The sample application loads different pipelines based on different application config files.
There are 2 pipelines configured in the sample app.Lidar Triton inference for 3D objects detection and file dump.Lidar Triton inference and 3D objects detection and GLES 3D rendering.Inside these sample configurations, the inference model is a 3D TAO model based on PointPillar. For more details about PointPillar, seehttps://arxiv.org/abs/1812.05784.NoteTensorRT 8.5 has a bug for FP16 mode when converting this specific TAO model to TensorRT engine file. DeepStream fallback to FP32 mode for this release.This is a snapshot fordeepstream-lidar-inference-apprunning with lidar data inference objects detection and GLES 3D rendering with 3D bounding box display on screen.Prerequisites#You must have the following development packages installed:GStreamer-1.0GStreamer-1.0 Base PluginsX11 client-side librarylibyaml-cpp-devTo install these packages, execute the following command:sudoapt-getinstalllibgstreamer-plugins-base1.0-devlibgstreamer1.0-dev\libgstrtspserver-1.0-devlibx11-devlibyaml-cpp-devLidar Point Cloud to 3D Point Cloud Processing and Rendering#The application can be configured as different pipelines according to the application configuration file.Lidar data inference and 3D bounding box dump pipeline:This pipeline is from lidar point cloud, 3D point cloud inferencing, to the 3D objects data dump.This pipeline is setup by theconfig_lidar_triton_infer.yaml. It has 3 components:ds3d::dataloaderfor lidar pointcloud data file reading,ds3d::datafilterfor point-cloud Triton inferencing, andds3d::datarenderfor3D Bounding Boxfile dump.ds3d::dataloaderloads custom liblibnvds_lidarfileread.soand creates adataloaderthrough thecreateLidarFileLoaderfunction. This specific loader is configured by lidar dataset file listdata_config_file.Gst-appsrcconnects thedataloaderinto the deepstream pipeline.name:lidarsourcetype:ds3d::dataloaderout_caps:ds3d/datamapcustom_lib_path:libnvds_lidarfileread.socustom_create_function:createLidarFileLoaderds3d::datafilterloads custom liblibnvds_tritoninferfilter.soand creates a lidar point cloud Triton inferencing filter through thecreateLidarInferenceFilterfunction. For this specific configuration, The Lidar Triton filter inferences the point cloud data with TAO modelPointPillarNet modeland return the 3D bounding boxes around each object.name:lidarfiltertype:ds3d::datafilterin_caps:ds3d/datamapout_caps:ds3d/datamapcustom_lib_path:libnvds_tritoninferfilter.socustom_create_function:createLidarInferenceFilterds3d::datafilteris loaded by thenvds3dfilterGst-pluginwhich acceptsin_capsassink_capsandout_capsassrc_caps. It creates a customds3d::datafilterinstance and processess data asds3d/datamap.ds3d::datarenderloads custom liblibnvds_lidarfilewrite.soto dump the detected 3D bounding boxes to a file.name:lidarrendertype:ds3d::datarenderin_caps:ds3d/datamapcustom_lib_path:libnvds_lidarfilewrite.socustom_create_function:createLidarFileDataRenderLidar data inference and Lidar data rendering with 3D bounding box display pipeline:This pipeline is from lidar point cloud data file, 3D point cloud inferencing, to the 3D point cloud rendering with colors.This pipeline is setup by theconfig_lidar_source_triton_render.yaml. It has 3 components:ds3d::dataloaderfor lidar pointcloud data file reading,ds3d::datafilterfor point-cloud Triton inferencing, andds3d::datarenderfor Lidar 3D dataLidarXYZIand3D Bounding Boxrendering.ds3d::dataloaderloads custom liblibnvds_lidarfileread.soand creates adataloaderthrough thecreateLidarFileLoaderfunction. This specific loader is configured by lidar dataset file listdata_config_file.Gst-appsrcconnects thedataloaderinto the deepstream pipeline.name:lidarsourcetype:ds3d::dataloaderout_caps:ds3d/datamapcustom_lib_path:libnvds_lidarfileread.socustom_create_function:createLidarFileLoaderds3d::datafilterloads custom liblibnvds_tritoninferfilter.soand creates a lidar point cloud Triton inferencing filter through thecreateLidarInferenceFilterfunction. For this specific configuration, The Lidar Triton filter inferences the point cloud data with TAO modelPointPillarNet modeland return the 3D bounding boxes around each object.name:lidarfiltertype:ds3d::datafilterin_caps:ds3d/datamapout_caps:ds3d/datamapcustom_lib_path:libnvds_tritoninferfilter.socustom_create_function:createLidarInferenceFilterds3d::datafilteris loaded by thenvds3dfilterGst-pluginwhich acceptsin_capsassink_capsandout_capsassrc_caps. It creates a customds3d::datafilterinstance and processess data asds3d/datamap.ds3d::datarenderloads custom liblibnvds_3d_gl_datarender.soand creates GLES Lidar point cloud rendering context to display XYZI or XYZ lidar data and 3D bounding boxes withcustom_create_function:createLidarDataRender.name:lidarrendertype:ds3d::datarenderin_caps:ds3d/datamapcustom_lib_path:libnvds_3d_gl_datarender.socustom_create_function:createLidarDataRenderGetting Started#Run Lidar Point Cloud Data File reader, Point Cloud Inferencing filter, and Point Cloud 3D rendering and data dump Examples#PreparePointPillarNet modeland Triton environment, this app will use Triton to do inference, for more details of Triton Inferencing Server, refer tohttps://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinferserver.html.Follow instructions in deepstream-lidar-inference-app/README to prepare testing resources and Triton CAPI and gRPC environments.Run the lidar point cloud data inference pipeline in 2 modes.Run lidar data reader, point cloud 3D objects detection inference and 3D data GLES rendering pipeline:$deepstream-lidar-inference-app-cconfigs/config_lidar_source_triton_render.yamlRun lidar data reader, point cloud 3D objects inference and 3D objects file dump pipeline:$deepstream-lidar-inference-app-cconfigs/config_lidar_triton_infer.yamlThis part sets up a lidar point cloud loaderdataloader. It then streamsds3d/datamapto the downstreamdatafiltercomponentlidarfilter.name:lidarsourcetype:ds3d::dataloaderout_caps:ds3d/datamapcustom_lib_path:libnvds_lidarfileread.socustom_create_function:createLidarFileLoaderIt streamsds3d/datamapto thenvds3dfilterGst-pluginwhich loadslidarfilterto do Triton inferencing on point cloud. For more details onnvds3dfilterGst-plugin, SeeGst-nvds3dfilter.name:lidarfiltertype:ds3d::datafilterin_caps:ds3d/datamapout_caps:ds3d/datamapcustom_lib_path:libnvds_tritoninferfilter.socustom_create_function:createLidarInferenceFilterField ofmodel_inputsis the description of the model input layers. Includes layer name, layer data type and layer dimensions.model_inputs:
- name: points      # name of the 1st layer
  datatype: FP32    # data type of the 1st layer
  shape: [1, 204800, 4] # data dimension of the 1st layer
- name: num_points  # name of the 2nd layer
  datatype: INT32   # data type of the 2nd layer
  shape: [1]        # data dimension of the 2nd layerField ofmodel_outputsis the description of the model output layers. Includes layer name, layer data type and layer dimensions.model_outputs:
- name: output_boxes # name of the 1st layer
  datatype: FP32     # data type of the 1st layer
  shape: [1, 393216, 9] # data dimension of the 1st layer
- name: num_boxes    # name of the 2nd layer
  datatype: INT32    # data type of the 2nd layer
  shape: [1]         # data dimension of the 2nd layerField oflabelsis the label list of the point cloud inferencing model.labels:          # YAML list for object labels
- Vehicle
- Pedestrian
- CyclistFinally the data stream asds3d/datamapis delivered to the render component.3D detection file dump componentlidarfiledump.name: lidarfiledump
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_lidarfilewrite.so
custom_create_function: createLidarFileDataRenderGLES lidar data rendering componentlidardatarender.name: lidardatarender
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_3d_gl_datarender.so
custom_create_function: createLidarDataRenderCheck the/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-lidar-inference-app/READMEfile for more details.DeepStream Lidar Inference App Configuration Specifications#deepstream-lidar-inference-app[ds3d::userapp]group settings#The table below demonstrates the group settings forconfig_lidar_triton_infer.yamlandconfig_lidar_source_triton_render.yamlas the examples.point cloud inferencing app user debug supported settings#GroupPropertyMeaningType and RangeExampleLidarFileLoaderdata_config_filelidar data list file pathstringdata_config_file: lidar_data_list.yamlLidarFileLoaderpoints_numnumber of the points in pointcloud filefixed valuepoints_num: 204800LidarFileLoaderlidar_datatypedata type of the datasetString:FP32 FP16 INT8 INT32lidar_datatype: FP32LidarFileLoadermem_typememory type of processdata:justsupport cpu nowString:gpu cpumem_type: cpuLidarFileLoadermem_pool_sizeSize of the data read poolInteger: >0mem_pool_size: 4LidarFileLoaderoutput_datamap_keydatamap key in lidarsourcestringoutput_datamap_key: DS3D::LidarXYZILidarFileLoaderfile_loopflag for file reading loopbooleanfile_loop: FalseLidarInferenceFilterin_streamswhich data type will be processedfixed valuein_streams: [lidar]LidarInferenceFiltermem_pool_sizeSize of the input tensor poolIntegermem_pool_size: 8LidarInferenceFiltermodel_inputsmodel â€˜s input layersArrayrefer to config_lidar_triton_infer.yamlLidarInferenceFiltermodel_outputsmodel â€˜s output layersArrayrefer to config_lidar_triton_infer.yamlLidarInferenceFilterinput_tensor_mem_typeinput tensor memory type after preprocessString:GpuCuda CpuCudainput_tensor_mem_type: GpuCudaLidarInferenceFiltercustom_preprocess_lib_pathpreprocessing library pathStringcustom_preprocess_lib_path: /opt/nvidia/deepstream/deepstream/lib/libnvds_lidar_custom_preprocess_impl.soLidarInferenceFiltercustom_preprocess_func_namecustomized preprocessing function nameStringcustom_preprocess_func_name: CreateInferServerCustomPreprocessLidarInferenceFilterlabelslabel list for the detection modelArrayrefer to config_lidar_triton_infer.yamlLidarInferenceFilterpostprocess_nms_iou_threshNMS IOU thresholdFloatpostprocess_nms_iou_thresh: 0.01LidarInferenceFilterpostprocess_pre_nms_top_nnumber of TOPs of NMSIntegerpostprocess_nms_top_n: 4096LidarInferenceFilterconfig_filenvinferserver configuration fileStringconfig_file: triton_mode_CAPI.txtLidarInferenceFiltergpu_idGPU id for the tensor memory(for native Triton Server Inferencing)Integergpu_id: 0LidarInferenceFilterfilter_input_datamap_keyinput datamap key from lidarsourceStringfilter_input_datamap_key: DS3D::LidarXYZILidarFileDataRenderframes_save_paththe path of the dump fileStringframes_save_path: ../data/LidarFileDataRenderinput_datamap_keyinput key from the custom_postprocess for inferencing objectsStringinput_datamap_key: DS3D::Lidar3DBboxRawDataLidarDataRendertitlethe title of the renderStringtitle: ds3d-lidar-renderLidarDataRenderstreamsthe stream key(s) for the input to be renderedListstreams: [lidardata]LidarDataRenderwidthrender area widthIntegerwidth: 1280LidarDataRenderheightrender area heightIntegerheight: 720LidarDataRenderblockthe flag of enabling block functionBooleanblock: TrueLidarDataRenderview_positionthe view position for lookat vectorListview_position: [0, 0, 80]LidarDataRenderview_targetthe view target for lookat vectorListview_target: [0, 0, 0]LidarDataRenderview_upthe up vector of the visualizerListview_up: [1, 0, 0]LidarDataRendernearthe near z-plane of the visualizer constanceFloatnear: 0.3LidarDataRenderfarthe far z-plane of the visualizer constanceFloatfar: 100LidarDataRenderfovdegree for field of viewIntegerfov: 45LidarDataRenderlidar_colorthe RGB color description of the lidar dataList,lidar_color: [0, 255, 0]LidarDataRenderlidar_data_keythe lidar data key name in datamapStringlidar_data_key: DS3D::LidarXYZILidarDataRenderelement_sizethe lidar data element size (4, XYZI or 3, XYZ)Integerelement_size: 4LidarDataRenderlidar_bbox_keythe 3D bbox data key name in datamapStringDS3D::Lidar3DBboxRawDataLidarDataRenderenable_labelIndicate flag to enable labels renderingBooleanenable_label: TrueDS3D Custom Components Configuration Specifications#See more details in theDS_3D supported custom components specificationssection in theDeepStream-3D Custom Apps and Libs Tutorials.Build application From Source#Go to the foldersources/apps/sample_apps/deepstream-lidar-inference-app.Run the following commands:$ sudo make
$ sudo make installNoteCheck the source code for more details on how to loaddataloader/datarenderthroughGst-appsrcandGst-appsink.datafilteris loaded by thenvds3dfilterGst-plugin.previousDeepStream 3D Depth Camera AppnextNetworked Media Open Specifications (NMOS) in DeepStreamOn this pagePrerequisitesLidar Point Cloud to 3D Point Cloud Processing and RenderingGetting StartedRun Lidar Point Cloud Data File reader, Point Cloud Inferencing filter, and Point Cloud 3D rendering and data dump ExamplesDeepStream Lidar Inference App Configuration Specificationsdeepstream-lidar-inference-app[ds3d::userapp]group settingsDS3D Custom Components Configuration SpecificationsBuild application From SourcePrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright Â© 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.