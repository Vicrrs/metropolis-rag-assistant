DeepStream 3D Action Recognition App — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formDeepStream...DeepStream 3D Action Recognition App#Thedeepstream-3d-action-recognitionsample application is provided atapp/sample_apps/deepstream-3d-action-recognitionfor your reference. This example demonstrates a sequence batching based 3D or 2D model inference pipeline for action recognition. The image below shows the architecture of this reference app.Gst-nvdspreprocessplugin re-processses the input tensors forGst-nvinferplugin.Gst-nvdspreprocessloads acustom_sequence_preprocess lib(subfolder) to perform temporal sequence batching and ROI spatial batching. It delivers the preprocessed batched tensor buffers into downstream pluginGst-nvinferfor inference. This application probes the tensor data and action classification result, converts them into display metadata to print on screen.
This 3D/2D model is pretrained by NVIDIA TAO toolkit. The 3D model has NCDHW (NCSHW) input and the 2D model has NSHW shapes.N:MaxbatchsizeoftotalnumberofROIsinallstreams,value>0.C:Channelnumbers,mustbe3.D/S:sequencelengthofconsecutiveframes,value>1H:height,value>0W:width,value>02DS:channelsxsequence_length,reshapedfrom[C,D]A custom sequence preprocessing lib:libnvds_custom_sequence_preprocess.sois also provided atsources/apps/sample_apps/deepstream-3d-action-recognition/custom_sequence_preprocessto demonstrate how to implement a sequence batching and preprocessing methods withGst-nvdspreprocessplugin. This custom lib normalizes each incoming ROI cropped image and accumulates the data into buffer sequence for temporal batching. When temporal batching is ready, it continues to do spacial batching on multi-ROIs and multi-streams. Finally it returns the temporal and spacial batched buffer(tensor) toGst-nvdspreprocessplugin which would attach the buffer as preprocess input metadata and deliver to downstreamGst-nvinferplugin to do inference.Getting Started#Prerequisites#Go to the foldersources/apps/sample_apps/deepstream-3d-action-recognition.Search and Download 3D and 2D RGB basedtao_iva_action_recognition_pretrainedmodels from NGChttps://ngc.nvidia.com/catalog/models/nvidia:tao:actionrecognitionnet(Version 5):resnet18_3d_rgb_hmdb5_32resnet18_2d_rgb_hmdb5_32These Models support following classes :push;fall_floor;walk;run;ride_bike.Update source streamsuri-listin action recognition config file:deepstream_action_recognition_config.txt.uri-list=file:///path/to/sample_action1.mov;file:///path/to/sample_action2.mov;file:///path/to/sample_action3.mov;file:///path/to/sample_action4.mov;Export DISPLAY environment to correct display. e.g.export DISPLAY=:0.0.Run 3D Action Recognition Examples#Make sure 3D preprocess config and 3D inference config are enabled indeepstream_action_recognition_config.txt.# Enable 3D preprocess and inferencepreprocess-config=config_preprocess_3d_custom.txtinfer-config=config_infer_primary_3d_action.txtRun the following command:$deepstream-3d-action-recognition-cdeepstream_action_recognition_config.txtRun with DS-Triton, update application config filedeepstream_triton_action_recognition_config.txt.preprocess-config=config_preprocess_3d_custom.txttriton-infer-config=config_triton_infer_primary_3d_action.txtRun 3D test with DS-Triton:$ ./deepstream-3d-action-recognition -c deepstream_triton_action_recognition_config.txtChecksources/TritonOnnxYolo/READMEfor more details how to switch action recognition DS-Triton tests between CAPI and gRPC.Run 2D Action Recognition Examples#Make sure 2D preprocess config and 2D inference config are enabled indeepstream_action_recognition_config.txt.# Enable 2D preprocess and inference
preprocess-config=config_preprocess_2d_custom.txt
infer-config=config_infer_primary_2d_action.txtRun the following command:$deepstream-3d-action-recognition-cdeepstream_action_recognition_config.txtRun with DS-Triton, update application config filedeepstream_triton_action_recognition_config.txt.preprocess-config=config_preprocess_2d_custom.txt
triton-infer-config=config_triton_infer_primary_2d_action.txtRun 2D test with DS-Triton:$ ./deepstream-3d-action-recognition -c deepstream_triton_action_recognition_config.txtChecksources/TritonOnnxYolo/READMEfor more details how to switch action recognition DS-Triton tests between CAPI and gRPC.DeepStream 3D Action Recognition App Configuration Specifications#deepstream-3d-action-recognition[action-recognition]group settings#The table below demonstrates the group settings fordeepstream_action_recognition_config.txtas an example.3D action recognition Supported Settings#PropertyMeaningType and RangeExampleuri-listsource video file or stream listSemicolon delimited string listfile:///path/to/sample_action1.mp4;file:///path/to/sample_action2.mp4;display-syncIndicate display synchronization on timestamp or notBooleandisplay-sync=1preprocess-configGst-nvdspreprocess plugin config file pathStringpreprocess-config=config_preprocess_3d_custom.txtinfer-configGst-nvinfer plugin config file pathStringinfer-config=config_infer_primary_2d_action.txtmuxer-heightGst-nvstreammux heightUnsigned Integermuxer-height=720muxer-widthGst-nvstreammux widthUnsigned Integermuxer-width=1280muxer-batch-timeoutGst-nvstreammux batched push timeout in usecUnsigned Integermuxer-batch-timeout=40000tiler-heightGst-nvmultistreamtiler heightUnsigned Integertiler-height=720tiler-widthGst-nvmultistreamtiler widthUnsigned Integertiler-width=1280debugLog print debug levelInteger, 0: disabled. 1: debug. 2: verbosedebug=0enable-fpsIndicate whether print fps on screenBooleanenable-fps=1Custom sequence preprocess lib user settings[user-configs]forgst-nvdspreprocess#The table below demonstrates theconfig_preprocess_3d_custom.txtsetting oflibnvds_custom_sequence_preprocess.soas an example.user-configs properties for custom sequence preprocess#PropertyMeaningType and RangeExamplechannel-scale-factorsscale factor list for each channelSemicolon delimited float arraychannel-scale-factors=
0.007843137;0.007843137;0.007843137channel-mean-offsetsdata mean offsets for each channelSemicolon delimited float arraychannel-mean-offsets=127.5;127.5;127.5stridesequence sliding stride for each batched sequneceUnsigned Integer, value >= 1stride=1subsampleSubsample rates for inference images in each sequenceUnsigned Integer, value >= 0subsample=0Customliband`gst-nvdspreprocess`Settings for Action Recognition#You’ll need to set input order as CUSTOMnetwork-input-order=2for this custom sequence preprocess lib.3D models NCDHW(NCSHW) require network-input-shape with 5-dimension shape. For example:network-input-shape=4;3;32;224;224Itmeansmax_batch_size:4,channels3,sequence_len:32,height224,width224.2D models NSHW require network-input-shape with 4-dimension shape. For example:network-input-shape=4;96;224;224Itmeansmax_batch_size:4,channels3,sequence_len:32,height224,width224.where96=channelsxsequence_len.Assume incoming frame numbers are 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15… Whensubsample=1, the preprocessing custom lib will pick up frame numbers: 1,3,5,7,9… to preprocess sequentially and  pass it onto inference as a next-step.Assuming same incoming frame numbers above, For example, whensubsample=0, stride=1, the 2 consecutive sliding sequences are:BatchA:[1,2,3,4,5...]BatchB:[2,3,4,5,6...]Whensubsample=0, stride=2, the 2 consecutive sliding sequences are:Batch A: [1,2,3,4,5...]
Batch B: [3,4,5,6,7...]Whensubsample=1, stride=2, the subsample is performed first, and sliding sequences are on top of subsample results. The processing frame numbers after subsample are: 1,3,5,7,9,11,13,15,17,19… The consecutive sliding sequences on top of them are:Batch A: [1,3,5,7,9...]
Batch B: [5,7,9,11,13...] # 1st frame sliding from frame 1 of Batch A to frame 5
Batch C: [9,11,13,15,17...] # 1st frame sliding from frame 5 of Batch C to frame 9The image below shows the frame batches with different subsample and stride settings.Build Custom sequence preprocess lib and application From Source#Go to the foldersources/apps/sample_apps/deepstream-3d-action-recognition.Run the following commands:$make$makeinstallCheck the source code and comments to learn about implementation of other order formats, for example, NSCHW (NDCHW).previousDeepStream With REST API SevernextDeepStream 3D Depth Camera AppOn this pageGetting StartedPrerequisitesRun 3D Action Recognition ExamplesRun 2D Action Recognition ExamplesDeepStream 3D Action Recognition App Configuration Specificationsdeepstream-3d-action-recognition[action-recognition]group settingsCustom sequence preprocess lib user settings[user-configs]forgst-nvdspreprocessCustomliband`gst-nvdspreprocess`Settings for Action RecognitionBuild Custom sequence preprocess lib and application From SourcePrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.