Creating an AI Application — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formCreating an...Creating an AI Application#Previous section explained how to run pre-created DeepStream test1 application. This section will explain how to create DeepStream test1 application from scratch using Composer.Launch Composer#Launch Composer tool using following command:composerDrag and Drop Components#DeepStream pipeline primarily depends onGstreamerplugins which are represented byINvDsElementbase type in Graph Composer. UseGroupBybutton to list the components by their base type. All the components underINvDsElementrepresentGStreamerplugins.DeepStreamtest1application detects people in the single batch video source and renders the output on display with bounding boxes. It requires the following:Source plugin component for inputMuxplugin component as infer plugin component requires mux before itVideo inference plugin component withpeoplenetmodelOSDplugin component to draw bounding boxesRenderplugin component to display outputAll these components are available in the extensions published to NVIDIA Cloud repository and can be browsed in component list window of the Composer. You can drag and drop these components from component list window to canvas.Refer to theDeepStream Componentsfor all the components supported by DeepStream.Configure Components#Component’s parameters can be configured once these are added to the canvas by selecting the component on canvas. If property is not updated then it uses default value hence not all properties are required to be set. Configure components by setting properties to expected valuesSet input file path in source component, eg “/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4”Set batch size and GPU ID in mux, eg “0”Set inference model to use in video inference component, eg “nvidia::deepstream::NvDsResnet18_4ClassDetectorModel”NotePlugin component (INvDsElement) properties match 1:1 with GStreamer plugin properties.NoteNvDsInferVideoandNvInferAudiocomponents have special connector infer-model-config which allows users to connectINvDsInferModelConfigComponentcomponents. Users can package infer config file along with other model related files in these components. Using this config is optional and users can also directly program the infer config file path in the config-file-path property.Connect Components#It is required to connect input/output ports of the components to the establish data transfer. Input/output ports ofINvDsElementmatch 1:1 withGstreamerplugin pads. Current Composer does not validate input/output data type in this release, it will just check if the input/output handles are compatible. Data type validation is planned for future release. Users can match port types using names e.g. video-out, video-in, audio-out, audio-in etc. Only out and in ports can be connected to each other, in to in or out to out connections are not allowed.Add GStreamer Scheduler#DeepStream components uses DeepStream andGStreamerplugins which requiresGStreamerruntime to execute the pipeline.GStreamerscheduler component handles backgroundGStreamerfunctionality to create and execute pipeline from graph.Count Number Of People#How to add some more functionality to this inference pipeline such as measuring FPS or counting objects? Let’s add people counting to this pipeline since we used people detection network.People counting component is added as a probe handler on output video port. Probe handler components registers callbacks which are called whenever data is available on the connected port. It allows users to process the data from the ports, these handlers can either add new data to theGstBufor modify the existingGstBuf.Save Graph#Graph can be saved by right clicking on canvas. Follow instructions fromGraphComposer_Graph_Runtimeto run the application using saved.yamlgraph file. Refer to Container Builder config files in/opt/nvidia/deepstream/deepstream-7.1/reference_graphs/deepstream-test1as a reference to create new config for the saved graph.Use Multiple inputs#You can add multipleNvDsSingleSrcInputcomponents and connect toMvDsStreamMuxcomponent. This does not allow runtime add/remove of inputs.Runtime add/remove inputs#There isNvDsMultiSrcInputcomponent which is based on aGstreambin. It takes list of inputs as property allowing runtime changes in the list through runtime manipulator component, smart record start/stop. Runtime add/remove and smart record start/stop signals can be triggered by other components. You can implement your custom components to trigger these actions, for example, cloud message, keyboard event etc.,previousApplication Development WorkflownextReference graphsOn this pageLaunch ComposerDrag and Drop ComponentsConfigure ComponentsConnect ComponentsAdd GStreamer SchedulerCount Number Of PeopleSave GraphUse Multiple inputsRuntime add/remove inputsPrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.