Gst-nvdspostprocess in DeepStream â€” DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formGst-nvdspost...Gst-nvdspostprocess in DeepStream#The Gst-nvdspostprocess plugin is released in DeepStream 6.1. The plugin supports parsing of various inferencing models
in DeepStream SDK. The plugin can perform parsing on the tensors of the output layers provided by the Gst-nvinfer and Gst-nvinferserver.
The aim of this document is to provide guidance on how to use the Gst-nvdspostprocess plugin for various inference models.This document provides details about: The document is divided into four parts.Detector modelssuch as Yolo V3 and Faster RCNN.Using classification model asPrimary Classification modelwith Gst-nvinferserverMask RCNN Model.Also provides a table for using various custom functions that can be used for parsing of output layers.Detector models#To use Yolo V3 detector, follow the prerequisite steps mentioned in/opt/nvidia/deepstream/deepstream/sources/objectDetector_Yolo/README.Check if the setup is configured correctly by running below test pipelines in following folder/opt/nvidia/deepstream/deepstream/sources/objectDetector_Yolo/.#For dGPUgst-launch-1.0filesrclocation=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4!decodebin!\m.sink_0nvstreammuxname=mbatch-size=1width=1920height=1080!nvinferconfig-file-path=config_infer_primary_yoloV3.txt!\nvvideoconvert!nvdsosd!nveglglessinksync=0#For Jetsongst-launch-1.0filesrclocation=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4!decodebin!\m.sink_0nvstreammuxname=mbatch-size=1width=1920height=1080!nvinferconfig-file-path=config_infer_primary_yoloV3.txt!\nvvideoconvert!nvdsosd!nv3dsinksync=0To update the above pipeline to use the post processing plugin for parsing, the/opt/nvidia/deepstream/deepstream/sources/objectDetector_Yolo/config_infer_primary_yoloV3.txtfile must be modified by:changing thenetwork-type=0tonetwork-type=100. By doing this, output post processing is disabled in nvinfer plugin.Set theoutput-tensor-meta=1, nvinfer plugin then attaches the tensor meta to the input buffer.Store the  modified file asconfig_infer_primary_yoloV3_modified.txt. The post processing plugin config file in YAML format has to be created as below.property:
 gpu-id: 0 #Set the GPU id
 process-mode: 1 # Set the mode as primary inference
 num-detected-classes: 80 # Change according the models output
 gie-unique-id: 1  # This should match the one set in inference config
 ## 1=DBSCAN, 2=NMS, 3= DBSCAN+NMS Hybrid, 4 = None(No clustering)
 cluster-mode: 2  # Set  appropriate clustering algorithm
 network-type: 0  # Set the network type as detector
 labelfile-path: labels.txt # Set the path of labels wrt to this config file
 parse-bbox-func-name: NvDsPostProcessParseCustomYoloV3 # Set custom parsing function

class-attrs-all: # Set as done in the original infer configuration
 nms-iou-threshold: 0.5
 pre-cluster-threshold: 0.7Save the above config asconfig_detector.yml. The following pipeline can be executed as given below.#For dGPUgst-launch-1.0filesrclocation=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4!decodebin!\sink_0nvstreammuxname=mbatch-size=1width=1920height=1080!nvinferconfig-file-path=config_infer_primary_yoloV3_modified.txt!\nvdspostprocesspostprocesslib-config-file=config_detector.yml\postprocesslib-name=/opt/nvidia/deepstream/deepstream/lib/libpostprocess_impl.so!nvvideoconvert!nvdsosd!nveglglessinksync=0#For Jetsongst-launch-1.0filesrclocation=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4!decodebin!\sink_0nvstreammuxname=mbatch-size=1width=1920height=1080!nvinferconfig-file-path=config_infer_primary_yoloV3_modified.txt!\nvdspostprocesspostprocesslib-config-file=config_detector.yml\postprocesslib-name=/opt/nvidia/deepstream/deepstream/lib/libpostprocess_impl.so!nvvideoconvert!nvdsosd!\nv3dsinksync=0NoteTheNvDsPostProcessParseCustomYoloV3function is defined in/opt/nvidia/deepstream/deepstream/sources/gst-plugins/gst-nvdspostprocess/postprocesslib_impl/post_processor_custom_impl.cppProcess similar to the above can be followed to demonstrate the usage of Faster RCNN network (/opt/nvidia/deepstream/deepstream/sources/objectDetector_FasterRCNN/README),  with nvdspostprocess plugin with belowconfig_detector.ymlproperty:
  gpu-id: 0 #Set the GPU id
  process-mode: 1 # Set the mode as primary inference
  num-detected-classes: 21 # Change according the models output
  gie-unique-id: 1  # This should match the one set in inference config
  ## 1=DBSCAN, 2=NMS, 3= DBSCAN+NMS Hybrid, 4 = None(No clustering)
  cluster-mode: 2  # Set  appropriate clustering algorithm
  network-type: 0  # Set the network type as detector
  labelfile-path: labels.txt # Set the path of labels wrt to this config file
  parse-bbox-func-name: NvDsPostProcessParseCustomFasterRCNN # Set custom parsing function FRCNN

class-attrs-all: # Set as done in the original infer configuration
  topk: 20
  nms-iou-threshold: 0.4
  pre-cluster-threshold: 0.5

class-attrs-0:
  pre-cluster-threshold: 1.1The pipeline for running the Faster RCNN network with modified nvinfer config and post process plugin is given below.#For dGPU
gst-launch-1.0 filesrc location=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4 ! decodebin !  \
m.sink_0 nvstreammux name=m batch-size=1 width=1920  height=1080 ! nvinfer config-file-path=config_infer_primary_fasterRCNN_modified.txt ! \
nvdspostprocess postprocesslib-config-file=config_detector.yml postprocesslib-name=/opt/nvidia/deepstream/deepstream/lib/libpostprocess_impl.so ! \
nvvideoconvert ! nvdsosd ! nveglglessink sync=0

#For Jetson
gst-launch-1.0 filesrc location=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4 ! decodebin !  \
m.sink_0 nvstreammux name=m batch-size=1 width=1920  height=1080 ! nvinfer config-file-path=config_infer_primary_fasterRCNN_modified.txt ! \
nvdspostprocess postprocesslib-config-file=config_detector.yml postprocesslib-name=/opt/nvidia/deepstream/deepstream/lib/libpostprocess_impl.so ! \
nvvideoconvert ! nvdsosd ! nv3dsink sync=0Primary Classification model#The primary classification model is demonstrated using the DeepStream TritonDocker Containerson dGPU.
Once the docker is running the model repo and classification video should be created.NoteThe scriptprepare_classification_test_video.shmentioned below requiresffmpegto be installed. Some of the low level codec libraries need to be re-installed along with ffmpeg.Use the following command to install/re-install  ffmpeg:apt-getinstall--reinstalllibflac8libmp3lame0libxvidcore4ffmpegExecute following commands to download the model repo and create a sample classification video.cd /opt/nvidia/deepstream/deepstream/samples
./prepare_ds_triton_model_repo.sh
apt-get install --reinstall libflac8 libmp3lame0 libxvidcore4 ffmpeg
./prepare_classification_test_video.sh
cd /opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app-tritonCheck by running following sample classification pipelinegst-launch-1.0 filesrc location=/opt/nvidia/deepstream/deepstream/samples/streams/classification_test_video.mp4  ! decodebin ! \
m.sink_0 nvstreammux name=m batch-size=1 width=1920  height=1080 ! \
nvinferserver config-file-path=config_infer_primary_classifier_densenet_onnx.txt  \
! nvvideoconvert ! nvdsosd ! nveglglessink sync=1NoteTo use nveglglessink inside docker ensurexhost+done from the host, and set appropriateDISPLAYenvironment variable inside the docker.Now, update theconfig_infer_primary_classifier_densenet_onnx.txtto disable post processing and attaching tensor output meta in nvinferserver. This can be done by updating configuration file with following parametersinfer_config{postprocess{other{}}}andoutput_control{output_tensor_meta:true}infer_config {
 unique_id: 5
 gpu_ids: [0]
 max_batch_size: 1
 backend {
   triton {
     model_name: "densenet_onnx"
     version: -1
     model_repo {
       root: "../../triton_model_repo"
       strict_model_config: true
       tf_gpu_memory_fraction: 0.0
       tf_disable_soft_placement: 0
     }
   }
 }
 preprocess {
   network_format: IMAGE_FORMAT_RGB
   tensor_order: TENSOR_ORDER_LINEAR
   maintain_aspect_ratio: 0
   frame_scaling_hw: FRAME_SCALING_HW_DEFAULT
   frame_scaling_filter: 1
   normalize {
   scale_factor: 0.0078125
   channel_offsets: [128, 128, 128]
   }
 }
 #Disable post processing in nvinferserver
 postprocess {
   other {
   }
 }
 extra {
   copy_input_to_host_buffers: false
   output_buffer_pool_size: 2
 }
}
input_control {
 process_mode: PROCESS_MODE_FULL_FRAME
 interval: 0
}
#Enable attaching output tensor meta in nvinferserver
output_control {
 output_tensor_meta: true
}Save the above config asconfig_infer_primary_classifier_densenet_onnx_modified.txt. Create aconfig_classifier.ymlas given below.property:
 gpu-id: 0
 network-type: 1 # Type of network i.e. classifier
 process-mode: 1 # Operate in primary mode i.e. operate on full frame
 classifier-threshold: 0.2 #Set classifier threshold
 gie-unique-id: 5 # Set the unique_id matching one in the inference
 classifier-type: ObjectClassifier # type of classifier
 labelfile-path: /opt/nvidia/deepstream/deepstream/samples/triton_model_repo/densenet_onnx/densenet_labels.txt #Path of the labels fineThe following pipeline with nvdspostprocess plugin can now be executed to view the classification resultsgst-launch-1.0filesrclocation=/opt/nvidia/deepstream/deepstream/samples/streams/classification_test_video.mp4!decodebin!\m.sink_0nvstreammuxname=mbatch-size=1width=1920height=1080!nvinferserver\config-file-path=config_infer_primary_classifier_densenet_onnx_modified.txt!\nvdspostprocesspostprocesslib-config-file=config_classifier.ymlpostprocesslib-name=\/opt/nvidia/deepstream/deepstream/lib/libpostprocess_impl.so!nvvideoconvert!nvdsosd!nveglglessinksync=1Mask RCNN Model#To use the instance segmentation model follow the README in package/opt/nvidia/deepstream/deepstream/samples/configs/tao_pretrained_models/README.mdto obtain TAO toolkit config files and PeopleSegNet model.Once setup is done, execute following pipeline to validate the model.cd/opt/nvidia/deepstream/deepstream/samples/configs/tao_pretrained_modelsgst-launch-1.0filesrclocation=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4!decodebin!\m.sink_0nvstreammuxname=mbatch-size=1width=1920height=1080!nvinferconfig-file-path=config_infer_primary_peopleSegNet.txt!\nvvideoconvert!nvdsosddisplay-mask=1process-mode=0!nveglglessinksync=0NoteFor correct operation ensure the Tensor-RT OSS plugin is compiled and replaced as mentioned in the TAO README.As mentioned in earlier sections update the nvinfer configuration file to disable post processing and enable attaching tensor output meta. This is done by changing thenetwork-type=100andoutput-tensor-meta=1.Store the file by the nameconfig_infer_primary_peopleSegNet_modified.txt. Theconfig_mrcnn.ymlcan be created as given below.property:
 gpu-id: 0
 process-mode: 1 # Process on full frame
 num-detected-classes: 2 #Total Detected classes
 gie-unique-id: 1  #Match with gie-unique-id of inference config
 ## 1=DBSCAN, 2=NMS, 3= DBSCAN+NMS Hybrid, 4 = None(No clustering)
 cluster-mode: 4 # Disable clustering
 network-type: 3 # Network is instance segmentation
 labelfile-path: peopleSegNet_labels.txt
 parse-bbox-instance-mask-func-name: NvDsInferParseCustomMrcnnTLTV2

class-attrs-all:
 pre-cluster-threshold: 0.8Following pipeline can be used for testing the nvdspostprocess plugin with MRCNN network, using the above configuration files.gst-launch-1.0filesrclocation=/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4!decodebin!\m.sink_0nvstreammuxname=mbatch-size=1width=1920height=1080!\nvinferconfig-file-path=config_infer_primary_peopleSegNet.txt!\nvdspostprocesspostprocesslib-name=/opt/nvidia/deepstream/deepstream/lib/libpostprocess_impl.so\postprocesslib-config-file=config_mrcnn.yml!nvvideoconvert!nvdsosddisplay-mask=1process-mode=0!nveglglessinksync=0Custom Parsing functions#This section mentions the parsing functions present in postprocess library for available network architectures.Custom Parsing functions supported#Custom Parsing FunctionDescriptionNvDsPostProcessParseCustomResnetParsing Resnet 10 model packaged in DeepStreamNvDsPostProcessParseCustomTfSSDTensorflow/Onnx SSD detectorNvDsPostProcessParseCustomNMSTLTParsing TAO Toolkit Open Architecture Models SSD, FRCNN, DSSD, RetinaNetNvDsPostProcessParseCustomBatchedNMSTLTParsing of TAO Toolkit  Open Architecture Models Yolo V3, Yolo V4NvDsPostProcessParseCustomMrcnnTLTV2Parsing of TAO Toolkit  Open Architecture Model MaskRCNNNvDsPostProcessParseCustomFasterRCNNParsing of Faster R-CNN NetworkNvDsPostProcessClassiferParseCustomSoftmaxParsing Resnet 18 vehicle type classifier model packaged in DeepStreamNvDsPostProcessParseCustomSSDParsing of  SSD NetworkNvDsPostProcessParseCustomYoloV3Parsing of Yolo V3 NetworkNvDsPostProcessParseCustomYoloV3TinyParsing of Yolo V3 Tiny NetworkNvDsPostProcessParseCustomYoloV2Parsing of Yolo V2 NetworkNvDsPostProcessParseCustomYoloV2TinyParsing of Yolo V2 Tiny NetworkpreviousNetworked Media Open Specifications (NMOS) in DeepStreamnextDeepStream Can Orientation AppOn this pageDetector modelsPrimary Classification modelMask RCNN ModelCustom Parsing functionsPrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright Â© 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.