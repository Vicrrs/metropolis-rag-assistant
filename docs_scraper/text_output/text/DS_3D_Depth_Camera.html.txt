DeepStream 3D Depth Camera App — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formDeepStream...DeepStream 3D Depth Camera App#Thedeepstream-3d-depth-camerasample application is provided atapp/sample_apps/deepstream-3d-depth-camerafor your reference. This example demonstrates two different pipelines which bring depth camera from 2D into 3D world.
The depth and color data capture component is produced by Intel®RealSense™Depth Camera D435 series. For more details, seehttps://www.intelrealsense.com/depth-camera-d435/.Prerequisites#You must have the following development packages installed:GStreamer-1.0GStreamer-1.0 Base PluginsGStreamer-1.0 gstrtspserverX11 client-side librarylibyaml-cpp-devRealSense SDKTo install these packages, execute the following command:sudoapt-getinstalllibgstreamer-plugins-base1.0-devlibgstreamer1.0-dev\libgstrtspserver-1.0-devlibx11-devlibyaml-cpp-devFollow the RealSense SDK documentation to add RealSense public key and list of repositories. For x86, refer toIntelRealSense/librealsense. For Jetson platforms, refer toIntelRealSense/librealsense. You may use Ubuntu 20.04 source path into apt-repository to install dependencies.sudoadd-apt-repository"deb https://librealsense.intel.com/Debian/apt-repo bionic main"-uThen installlibrealsense2package to build and test.sudoapt-getinstalllibrealsense2-utilslibrealsense2-devMake sure RealSense SDK version is not earlier than 2.48.Plugin in Intel RealSense Depth D400 series USB camera. To verify the camera and upgrade firmware, runrealsense-viewerand update from the UI. Navigate to the foldersources/apps/sample_apps/deepstream-3d-depth-camera.If you are running these commands inside deepstream container, make sure camera devices are mounted in thedockerruncommand. For example:docker run --rm -it --gpus '"device=0"' --device /dev/video0 --device /dev/video1 --device /dev/video2 ...ExportDISPLAYenvironment to  the correct display. for example,exportDISPLAY=:0.0.Depth Color Capture to 2D Rendering Pipeline Overview#This is the first pipeline from the depth capture to 2D baseddepthmapto direct rendering with linear colors configured by the user.The pipeline is setup byds_3d_realsense_depth_capture_render.yaml. It has 2 components,ds3d::dataloaderfor depth/color anddatarenderforGLES 2Drender.ds3d::dataloaderloads custom liblibnvds_3d_dataloader_realsense.soand creates a RealSensedataloaderthrough thecreateRealsenseDataloaderfunction. This specific loader is configured for output streams of[color, depth].Gst-appsrcconnects thedataloaderinto the deepstream pipeline.name: realsense_dataloader
type: ds3d::dataloader
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_dataloader_realsense.so
custom_create_function: createRealsenseDataloaderds3d::datarenderloads custom liblibnvds_3d_gl_datarender.soand create aGLESrender through thecreateDepthStreamDataRenderfunction. This specific loader is configured for 2D depth and color images.Gst-appsinkconnects thedatarenderinto the deepstream pipeline.name:depth-rendertype:ds3d::datarenderin_caps:ds3d/datamapcustom_lib_path:libnvds_3d_gl_datarender.socustom_create_function:createDepthStreamDataRenderrealsense_dataloadercaptures color and depth streams inds3d/datamap, then delivers the data tods3d::datarendercomponentdepth-render.Depth Color Capture to 3D Point Cloud Processing and Rendering#The 2nd pipeline is from depth capture, 3D point cloud processing and alignment, to the 3D point cloud rendering with colors.The 2nd pipeline is setup by theds_3d_realsense_depth_to_point_cloud.yaml. It has 3 components:ds3d::dataloaderfor depth/color capture,ds3d::datafilterfor depth-to-point-cloud processing, anddatarenderforGLES 3Dpoints render.ds3d::dataloaderis the same as the 1st pipeline for depth and color capture. It also outputs the intrinsic parameters of the color/depth sensors, and extrinsic parameters from depth to color sensor module.name:realsense_dataloadertype:ds3d::dataloaderout_caps:ds3d/datamapcustom_lib_path:libnvds_3d_dataloader_realsense.socustom_create_function:createRealsenseDataloaderds3d::datafilterloads custom liblibnvds_3d_depth2point_datafilter.soand creates a depth-to-3D-point processing filter through thecreateDepth2PointFilterfunction. This specific filter generates the 3D point-cloud dataset from depth, and calculates a UV-coordinate map for correspondence between points and color position. It requires sensors’ intrinsic and extrinsic data fromdataloaderto make the alignment.name:point2cloud_datafiltertype:ds3d::datafilterin_caps:ds3d/datamapout_caps:ds3d/datamapcustom_lib_path:libnvds_3d_depth2point_datafilter.socustom_create_function:createDepth2PointFilterds3d::datafilteris loaded by thenvds3dfilterGst-pluginwhich acceptsin_capsassink_capsandout_capsassrc_caps. It creates a customds3d::datafilterinstance and processess data asds3d/datamap.ds3d::datarenderloads custom liblibnvds_3d_gl_datarender.soand create aGLESrender through thecreatePointCloudDataRenderfunction . This specific loader is configured for 3D points and colors rendering. It also supports 3D scene rotation based on mouse-drag.name:point-rendertype:ds3d::datarenderin_caps:ds3d/datamapcustom_lib_path:libnvds_3d_gl_datarender.socustom_create_function:createPointCloudDataRenderrealsense_dataloadercaptures color and depth streams along with  the intrinsic and extrinsic parameters of the sensor inds3d/datamap. It then delivers the data to the next componentpoint2cloud_datafilter. This component generates 3D point-cloud data and UV coordination map into new output datads3d/datamap. Finally, the data is delivered tods3d::datarendercomponentpoint-renderfor 3D rendering.Inside the configuration files,in_capsandout_capscorrespond to Gstreamer’ssink_capsandsrc_caps.Getting Started#Run RealSense Camera for Depth Capture and 2D Rendering Examples#Run the depth capture 2D render pipeline:$deepstream-3d-depth-camera-cds_3d_realsense_depth_capture_render.yamlThis sets up arealsensedataloader.name:realsense_dataloadertype:ds3d::dataloaderout_caps:ds3d/datamapcustom_lib_path:libnvds_3d_dataloader_realsense.socustom_create_function:createRealsenseDataloaderIt then streamsds3d/datamapto final the rendering component:depth-render.name:depth-rendertype:ds3d::datarenderin_caps:ds3d/datamapcustom_lib_path:libnvds_3d_gl_datarender.socustom_create_function:createDepthStreamDataRenderThedepth-rendercustom lib shall display the depth data and color data together in same window. Updatemin_depth/max_depthto remove foreground and background objects in the depth rendering. From RealSense specification,D435Camera depth range is between0.3and3meters.min_depth: 0.3 # in meters
max_depth: 2.0 # in metersUpdatemin_depth_color/min_depth_color[R, G, B] values to visualize color map of depth.min_depth_color: [255, 128, 0] # RGB color value for mininum depth
     max_depth_color: [0, 128, 255] # RGB color value for maximum depth

The other colors are linearly interpolated between ``min_depth_color`` and ``max_depth_color``Run 3D Depth Capture, Point Cloud filter, and 3D Points Rendering Examples#Run the depth capture and 3D processing pipeline:$ deepstream-3d-depth-camera -c ds_3d_realsense_depth_to_point_cloud.yamlThis sets up a realsensedataloader(same as 2D depth). It then streamsds3d/datamapto the downstreamdatafiltercomponentpoint2cloud_datafilter.name: realsense_dataloader
type: ds3d::dataloader
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_dataloader_realsense.so
custom_create_function: createRealsenseDataloaderIt streamsds3d/datamapto thenvds3dfilterGst-pluginwhich loadspoint2cloud_datafilterto convert 2D depth into 3D points. For more details onnvds3dfilterGst-plugin, SeeGst-nvds3dfilter.name: point2cloud_datafilter
type: ds3d::datafilter
in_caps: ds3d/datamap
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_depth2point_datafilter.so
custom_create_function: createDepth2PointFilterFinally the data stream asds3d/datamapis delivered to the render componentpoint-render.name: point-render
type: ds3d::datarender
in_caps: ds3d/datamap
custom_lib_path: libnvds_3d_gl_datarender.so
custom_create_function: createPointCloudDataRenderFields ofview_*are the eyes of the view position, similar to theOpenGLgluLookAt().view_position: [0, 0, -1] # view position in xyz coordinates
view_target: [0, 0, 1] # view target which is the direction pointing to
view_up: [0, -1.0, 0] # view up directionFields ofnear/far/fovare the perspective range of the eye, similar to theOpenGLgluPerspective().near: 0.01 # nearest points of perspective
far: 10.0 # farmost points of perspective
fov: 40.0 # FOV of perspectiveDeepStream 3D Depth Camera App Configuration Specifications#deepstream-3d-depth-camera[ds3d::userapp]group settings#The table below demonstrates the group settings fords_3d_realsense_depth_to_point_cloud.yamlas an example.3D depth camera app user debug supported settings#PropertyMeaningType and RangeExampletypeSpecify type ds3d::userappComponent type for user debugMust be type: ds3d::userappnameIndicate user-defined component nameStringname: debugdumpenable_debugIndicate whether enable debug logBooleanenable_debug: Falsedump_depthIndicate file location to dump depth raw dataStringdump_depth: depth_uint16_640x480.bindump_colorIndicate file location to dump color raw dataStringdump_color: color_rgba_1920x1080.bindump_pointsIndicate file location to dump 3D points raw data. datatype is Float and XYZ packedStringdump_points: pointxyz.binDS3D Custom Components Configuration Specifications#See more details in theDS_3D supported custom components specificationssection in theDeepStream-3D Custom Apps and Libs Tutorials.Build application From Source#Go to the foldersources/apps/sample_apps/deepstream-3d-depth-camera.Run the following commands:$ Set CUDA_VER in the MakeFile as per platform.
For both Jetson & x86, CUDA_VER=12.2
$ make
$ make installNoteCheck the source code for more details on how to loaddataloader/datarenderthroughGst-appsrcandGst-appsink.datafilteris loaded by thenvds3dfilterGst-plugin.previousDeepStream 3D Action Recognition AppnextDeepStream 3D Lidar Inference AppOn this pagePrerequisitesDepth Color Capture to 2D Rendering Pipeline OverviewDepth Color Capture to 3D Point Cloud Processing and RenderingGetting StartedRun RealSense Camera for Depth Capture and 2D Rendering ExamplesRun 3D Depth Capture, Point Cloud filter, and 3D Points Rendering ExamplesDeepStream 3D Depth Camera App Configuration Specificationsdeepstream-3d-depth-camera[ds3d::userapp]group settingsDS3D Custom Components Configuration SpecificationsBuild application From SourcePrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.