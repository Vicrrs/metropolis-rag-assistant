NvDsSampleModelsExt — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formExtensionsNvDsSampleModelsExtNvDsSampleModelsExt#Components for using the sample models provided as part of DeepStreamSDK.UUID: 909dc1ea-c654-44c1-97a3-0b8fec12141aVersion: 1.7.0Author: NVIDIALicense: ProprietaryComponents#nvidia::deepstream::NvDsResnet10_4ClassDetectorModel#4-class primary model detecting vehicles, persons, bicycles and roadsigns. Contains thecaffemodelandprototxt, labels file, INT8 calibration file and thenvinferconfiguration file for the model.Component ID: c2bed4f0-b9dd-43ab-b693-e0cbdd4f96e8Base Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#cluster-modeObject clustering mode to use.Valid values:1: DBSCAN2: NMS3: DBSCAN + NMS (Hybrid)4: No clusteringFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 2dbscan-min-scoreMinimum sum of confidence of all the neighbors in a cluster for it to be considered a valid cluster.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.0detected-max-hMaximum height in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64detected-max-wMaximum width in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64detected-min-hMinimum height in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0detected-min-wMinimum width in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0enable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: FalseepsEpsilon values for DBSCAN clustering algorithmFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.7infer-dimsBinding dimensions to set on the image input layer. Format - <dim1>;<dim2>;<dim3>…Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_STRINGinput-object-max-heightWhen used in secondary mode only on objects with this maximum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-max-widthWhen used in secondary mode only on objects with this maximum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-min-heightWhen used in secondary mode only on objects with this minimum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0input-object-min-widthWhen used in secondary mode only on objects with this minimum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0min-boxesMinimum number of points required to form a dense region for DBSCAN algorithmFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 3model-engine-filePath to the model engine file. Absolute or relative to the extension directory.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEnetwork-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1nms-iou-thresholdMaximum IOU score between two proposals after which the proposal with the lower confidence will be rejected.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.5post-cluster-thresholdDetection threshold to be applied post clustering operation for all classesFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.0pre-cluster-thresholdDetection threshold to be applied prior to clustering operation for all classesFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.4roi-bottom-offsetOffset of the RoI from the bottom of the frame. Only objects within the RoI are output.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0roi-top-offsetOffset of the RoI from the top of the frame. Only objects within the RoI are output.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0scaling-compute-hwCompute hardware to use for scaling frames / object crops to network resolution.Valid values:0: Platform default - GPU (dGPU), VIC (Jetson)1: GPU2: VIC (Jetson only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0scaling-filterThe filter to use for scaling frames / object crops to network resolution.Valid values:0: Nearest1: Bilinear2: Cubic(GPU)/5-Tap(VIC)3: Super(GPU)/10-Tap(VIC)4: Lanzos(GPU)/Smart(VIC)5: Nicest(VIC only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6topKKeep only top K objects with highest detection scores.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 20use-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0nvidia::deepstream::NvDsSecondaryCarColorClassifierModel#Secondary car color classification model. Contains thecaffemodelandprototxt, labels file, INT8 calibration file, the mean ppm file and thenvinferconfiguration file for the model.Component ID: f7a64e00-f01f-4eaf-8c94-d686c28b9e48Base Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#classifier-async-modeEnables inference on detected objects and asynchronous metadata attachments.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Trueclassifier-thresholdMinimum threshold label probability. The classifier outputs the label having the highest probability if it is greater than this thresholdFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.51enable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Falseinfer-dimsBinding dimensions to set on the image input layer. Format - <dim1>;<dim2>;<dim3>…Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_STRINGinput-object-max-heightWhen used in secondary mode only on objects with this maximum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-max-widthWhen used in secondary mode only on objects with this maximum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-min-heightWhen used in secondary mode only on objects with this minimum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 128input-object-min-widthWhen used in secondary mode only on objects with this minimum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 128model-engine-filePath to the model engine file. Absolute or relative to the extension directory.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEnetwork-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1scaling-compute-hwCompute hardware to use for scaling frames / object crops to network resolution.Valid values:0: Platform default - GPU (dGPU), VIC (Jetson)1: GPU2: VIC (Jetson only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0scaling-filterThe filter to use for scaling frames / object crops to network resolution.Valid values:0: Nearest1: Bilinear2: Cubic(GPU)/5-Tap(VIC)3: Super(GPU)/10-Tap(VIC)4: Lanzos(GPU)/Smart(VIC)5: Nicest(VIC only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6use-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0nvidia::deepstream::NvDsSecondaryCarMakeClassifierModel#Secondary car make classification model.  Contains thecaffemodelandprototxt, labels file, INT8 calibration file, the mean ppm file and thenvinferconfiguration file for the model.Component ID: f10b9a8c-d8d4-4ed8-ad54-8d8dca2392b9Base Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#classifier-async-modeEnables inference on detected objects and asynchronous metadata attachments.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Trueclassifier-thresholdMinimum threshold label probability. The classifier outputs the label having the highest probability if it is greater than this thresholdFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.51enable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Falseinfer-dimsBinding dimensions to set on the image input layer. Format - <dim1>;<dim2>;<dim3>…Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_STRINGinput-object-max-heightWhen used in secondary mode only on objects with this maximum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-max-widthWhen used in secondary mode only on objects with this maximum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-min-heightWhen used in secondary mode only on objects with this minimum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 128input-object-min-widthWhen used in secondary mode only on objects with this minimum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 128model-engine-filePath to the model engine file. Absolute or relative to the extension directory.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEnetwork-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1scaling-compute-hwCompute hardware to use for scaling frames / object crops to network resolution.Valid values:0: Platform default - GPU (dGPU), VIC (Jetson)1: GPU2: VIC (Jetson only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0scaling-filterThe filter to use for scaling frames / object crops to network resolution.Valid values:0: Nearest1: Bilinear2: Cubic(GPU)/5-Tap(VIC)3: Super(GPU)/10-Tap(VIC)4: Lanzos(GPU)/Smart(VIC)5: Nicest(VIC only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6use-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0nvidia::deepstream::NvDsSecondaryVehicleTypeClassifierModel#Secondary vehicle type classification model. Contains thecaffemodelandprototxt, labels file, INT8 calibration file, the mean ppm file and thenvinferconfiguration file for the model.Component ID: 47728594-4a13-4460-a906-32c3ae52a61aBase Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#classifier-async-modeEnables inference on detected objects and asynchronous metadata attachments.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Trueclassifier-thresholdMinimum threshold label probability. The classifier outputs the label having the highest probability if it is greater than this thresholdFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.51enable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Falseinfer-dimsBinding dimensions to set on the image input layer. Format - <dim1>;<dim2>;<dim3>…Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_STRINGinput-object-max-heightWhen used in secondary mode only on objects with this maximum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-max-widthWhen used in secondary mode only on objects with this maximum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-min-heightWhen used in secondary mode only on objects with this minimum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 128input-object-min-widthWhen used in secondary mode only on objects with this minimum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 128model-engine-filePath to the model engine file. Absolute or relative to the extension directory.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEnetwork-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1scaling-compute-hwCompute hardware to use for scaling frames / object crops to network resolution.Valid values:0: Platform default - GPU (dGPU), VIC (Jetson)1: GPU2: VIC (Jetson only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0scaling-filterThe filter to use for scaling frames / object crops to network resolution.Valid values:0: Nearest1: Bilinear2: Cubic(GPU)/5-Tap(VIC)3: Super(GPU)/10-Tap(VIC)4: Lanzos(GPU)/Smart(VIC)5: Nicest(VIC only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6use-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0nvidia::deepstream::NvDsSonyCAudioClassifierModel#Audio classifier trained on the SONYC urban noise database. Contains theonnxfile, labels file and thenvinferconfiguration file for the model.Component ID: d8d8f07e-3502-4124-ac4f-15f521cf2fb9Base Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#classifier-thresholdMinimum threshold label probability. The classifier outputs the label having the highest probability if it is greater than this thresholdFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.0enable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Falseinfer-dimsBinding dimensions to set on the image input layer. Format - <dim1>;<dim2>;<dim3>…Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_STRINGmodel-engine-filePath to the model engine file. Absolute or relative to the extension directory.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEnetwork-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6use-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0nvidia::deepstream::NvDsCarDetector360dModel#Car detector model for 360d use case.  Contains thecaffemodelandprototxt, labels file, INT8 calibration file and thenvinferconfiguration file for the model.Component ID: 8e3defe9-faf4-4417-945f-4ceb3950ca20Base Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#cluster-modeObject clustering mode to use.Valid values:1: DBSCAN2: NMS3: DBSCAN + NMS (Hybrid)4: No clusteringFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1dbscan-min-scoreMinimum sum of confidence of all the neighbors in a cluster for it to be considered a valid cluster.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.0detected-max-hMaximum height in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1920detected-max-wMaximum width in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1920detected-min-hMinimum height in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0detected-min-wMinimum width in pixels of detected objects to be output by the detectorFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0enable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: FalseepsEpsilon values for DBSCAN clustering algorithmFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.9infer-dimsBinding dimensions to set on the image input layer. Format - <dim1>;<dim2>;<dim3>…Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_STRINGinput-object-max-heightWhen used in secondary mode only on objects with this maximum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-max-widthWhen used in secondary mode only on objects with this maximum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64input-object-min-heightWhen used in secondary mode only on objects with this minimum heightFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0input-object-min-widthWhen used in secondary mode only on objects with this minimum widthFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0min-boxesMinimum number of points required to form a dense region for DBSCAN algorithmFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 3model-engine-filePath to the model engine file. Absolute or relative to the extension directory.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEnetwork-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 1nms-iou-thresholdMaximum IOU score between two proposals after which the proposal with the lower confidence will be rejected.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.5post-cluster-thresholdDetection threshold to be applied post clustering operation for all classesFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.0pre-cluster-thresholdDetection threshold to be applied prior to clustering operation for all classesFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.5roi-bottom-offsetOffset of the RoI from the bottom of the frame. Only objects within the RoI are output.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0roi-top-offsetOffset of the RoI from the top of the frame. Only objects within the RoI are output.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0scaling-compute-hwCompute hardware to use for scaling frames / object crops to network resolution.Valid values:0: Platform default - GPU (dGPU), VIC (Jetson)1: GPU2: VIC (Jetson only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0scaling-filterThe filter to use for scaling frames / object crops to network resolution.Valid values:0: Nearest1: Bilinear2: Cubic(GPU)/5-Tap(VIC)3: Super(GPU)/10-Tap(VIC)4: Lanzos(GPU)/Smart(VIC)5: Nicest(VIC only)Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6topKKeep only top K objects with highest detection scores.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 20use-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0previousNvDsSampleExtnextNvDsSourceExtOn this pageComponentsnvidia::deepstream::NvDsResnet10_4ClassDetectorModelParametersnvidia::deepstream::NvDsSecondaryCarColorClassifierModelParametersnvidia::deepstream::NvDsSecondaryCarMakeClassifierModelParametersnvidia::deepstream::NvDsSecondaryVehicleTypeClassifierModelParametersnvidia::deepstream::NvDsSonyCAudioClassifierModelParametersnvidia::deepstream::NvDsCarDetector360dModelParametersPrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.