NvDsActionRecognitionExt — DeepStream documentationSkip to main contentBack to topCtrl+KDeepStream documentationDeepStream documentationTable of ContentsDeepStream Getting StartedWelcome to the DeepStream DocumentationMigration GuideInstallationQuickstart GuideDocker ContainersDeepStream SamplesC/C++ Sample Apps Source DetailsPython Sample Apps and Bindings Source DetailsDeepStream Reference Application - deepstream-appDeepStream Reference Application - deepstream-test5 appDeepStream Reference Application - deepstream-nmos appDeepStream Reference Application on GitHubSample Configurations and StreamsImplementing a Custom GStreamer Plugin with OpenCV Integration ExampleTAO toolkit Integration with DeepStreamTAO Toolkit Integration with DeepStreamTutorials and How-to'sDeepStream-3D Custom Apps and Libs TutorialsDeepStream PerformancePerformanceDeepStream AccuracyAccuracy Tuning ToolsDeepStream Custom ModelUsing a Custom Model with DeepStreamDeepStream Key FeaturesDeepStream-3D Sensor Fusion Multi-Modal Application and FrameworkDeepStream-3D Multi-Modal BEVFusion SetupDeepStream-3D Multi-Modal V2XFusion SetupSmart Video RecordIoTOn the Fly Model UpdateNTP Timestamp in DeepStreamAV Sync in DeepStreamDeepStream With REST API SeverDeepStream 3D Action Recognition AppDeepStream 3D Depth Camera AppDeepStream 3D Lidar Inference AppNetworked Media Open Specifications (NMOS) in DeepStreamGst-nvdspostprocess in DeepStreamDeepStream Can Orientation AppDeepStream Application MigrationApplication Migration to DeepStream 7.1 from DeepStream 7.0DeepStream Plugin GuideGStreamer Plugin OverviewMetaData in the DeepStream SDKGst-nvdspreprocess (Alpha)Gst-nvinferGst-nvinferserverGst-nvtrackerGst-nvstreammuxGst-nvstreammux NewGst-nvstreamdemuxGst-nvmultistreamtilerGst-nvdsosdGst-nvdsmetautilsGst-nvdsvideotemplateGst-nvdsaudiotemplateGst-nvvideoconvertGst-nvdewarperGst-nvofGst-nvofvisualGst-nvsegvisualGst-nvvideo4linux2Gst-nvjpegdecGst-nvimagedecGst-nvjpegencGst-nvimageencGst-nvmsgconvGst-nvmsgbrokerGst-nvdsanalyticsGst-nvdsudpsrcGst-nvdsudpsinkGst-nvdspostprocess (Alpha)Gst-nvds3dfilterGst-nvds3dbridgeGst-nvds3dmixerGst-NvDsUcxGst-nvdsxferGst-nvvideotestsrcGst-nvmultiurisrcbinGst-nvurisrcbinDeepStream Troubleshooting and FAQTroubleshootingFrequently Asked QuestionsDeepStream On WSL2DeepStream On WSLFAQ for Deepstream On WSLDeepStream API GuideDeepStream API GuidesDeepStream Service MakerWhat is Deepstream Service MakerService Maker for C/C++ DevelopersService Maker for Python Developers(alpha)Quick Start GuideIntroduction to Flow APIsIntroduction to Pipeline APIsAdvanced FeaturesMigrating Traditional Deepstream Apps to Service Maker Apps in PythonWhat is a Deepstream Service Maker PluginDeepstream LibrariesDeepStream Libraries (Developer Preview)Graph ComposerOverviewPlatformsSupported platformsGetting StartedApplication Development WorkflowCreating an AI ApplicationReference graphsExtension Development WorkflowDeveloping Extensions for DeepStreamDeepStream ComponentsGXF InternalsGXF InternalsGraph eXecution EngineGraph Execution EngineGraph Composer ContainersGraph Composer and GXF ContainersGXF Component InterfacesGXF Component InterfacesGXF Application API'sGXF App C++ APIsGXF App Python APIsGXF Runtime API'sGXF Core C++ APIsGXF Core C APIsGXF Core Python APIsExtension ManualExtensionsCudaExtensionGXF Stream SyncStandardExtensionPython CodeletsNetworkExtensionNvTritonExtSerializationExtensionMultimediaExtensionVideoEncoderExtensionVideoDecoderExtensionBehavior TreesUCX ExtensionHttpExtensionGrpcExtensionTensorRTExtensionNvDs3dProcessingExtNvDsActionRecognitionExtNvDsAnalyticsExtNvDsBaseExtNvDsCloudMsgExtNvDsConverterExtNvDsDewarperExtNvDsInferenceExtNvDsInferenceUtilsExtNvDsInterfaceExtNvDsMuxDemuxExtNvDsOpticalFlowExtNvDsOutputSinkExtNvDsSampleExtNvDsSampleModelsExtNvDsSourceExtNvDsTemplateExtNvDsTrackerExtNvDsTranscodeExtNvDsTritonExtNvDsUcxExtNvDsUdpExtNvDsVisualizationExtToolsRegistryRegistry Command Line InterfaceComposerContainer BuilderGXF Command Line InterfacePipetuner GuideFAQ GuideFAQDeepStream Legal InformationDeepStream End User License AgreementDeepStream FeedbackFeedback formExtensionsNvDsActionRe...NvDsActionRecognitionExt#Components for using the NVIDIA TAO Toolkit Action Recognition modelsUUID: b7259b47-6df1-4774-b55f-ccd71e692c44Version: 1.6.0Author: NVIDIALicense: ProprietaryComponents#nvidia::deepstream::NvDsActionRecognition2D#Configuration for NVIDIA TAO 2D Action Recognition model.Recognizes actions Push, Fall, Walk, Run, Ride Bike.For more information:https://ngc.nvidia.com/catalog/models/nvidia:tao:actionrecognitionnetModel files must be downloaded and extracted to/opt/nvidia/deepstream/deepstream/samples/models/tao_pretrained_models/actionRecognitionComponent ID: deca38c1-5fcd-40f6-9c2a-95f4d83524caBase Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#model-engine-filePath to the model engine file. Absolute or relative to the extension directoy.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEenable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Falseuse-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6network-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 2classifier-thresholdMinimum threshold label probability. The classifier outputs the label having the highest probability if it is greater than this thresholdFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.0nvidia::deepstream::NvDsActionRecognition3D#Configuration for NVIDIA TAO 3D Action Recognition model.Recognizes actions Push, Fall, Walk, Run, Ride Bike.For more information:https://ngc.nvidia.com/catalog/models/nvidia:tao:actionrecognitionnetModel files must be downloaded and extracted to/opt/nvidia/deepstream/deepstream/samples/models/tao_pretrained_models/actionRecognitionComponent ID: 0ed5a99d-5445-4eeb-823b-3f6a2f77305eBase Type: nvidia::deepstream::INvDsInferModelConfigComponentParameters#model-engine-filePath to the model engine file. Absolute or relative to the extension directoy.Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FILEenable-dlaEnable DLA for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_BOOLDefault: Falseuse-dla-coreDLA Core to use for inferencingFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 0tensor-meta-pool-sizeSize of the output tensor meta poolFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 6network-modeData format to be used by inference.Valid values:0: FP321: INT82: FP16Flags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_UINT64Default: 2classifier-thresholdMinimum threshold label probability. The classifier outputs the label having the highest probability if it is greater than this thresholdFlags: GXF_PARAMETER_FLAGS_OPTIONALType: GXF_PARAMETER_TYPE_FLOAT64Default: 0.0previousNvDs3dProcessingExtnextNvDsAnalyticsExtOn this pageComponentsnvidia::deepstream::NvDsActionRecognition2DParametersnvidia::deepstream::NvDsActionRecognition3DParametersPrivacy Policy|Manage My Privacy|Do Not Sell or Share My Data|Terms of Service|Accessibility|Corporate Policies|Product Security|ContactCopyright © 2024-2025, NVIDIA Corporation.Last updated on Jan 13, 2025.